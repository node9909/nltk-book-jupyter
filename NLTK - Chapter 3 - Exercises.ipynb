{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to do many outputs per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Define a string s = 'colorless'. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colourless\n"
     ]
    }
   ],
   "source": [
    "s = 'colorless'\n",
    "s_new = s[:4] + 'u' + s[4:]\n",
    "prin☼ Describe the class of strings matched by the following regular expressions.\n",
    "\n",
    "[a-zA-Z]+\n",
    "[A-Z][a-z]*\n",
    "p[aeiou]{,2}t\n",
    "\\d+(\\.\\d+)?\n",
    "([^aeiou][aeiou][^aeiou])*\n",
    "\\w+|[^\\w\\s]+\n",
    "Test your answers using nltk.re_show().t(s_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ We can use the slice notation to remove morphological endings on words. For example,  'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish\n",
      "run\n",
      "nation\n",
      "un\n",
      "pre\n"
     ]
    }
   ],
   "source": [
    "str1 = 'dishes'\n",
    "str2 = 'running'\n",
    "str3 = 'nationality'\n",
    "str4 = 'undo'\n",
    "str5 = 'preheat'\n",
    "\n",
    "str1_new = str1[:4]\n",
    "str2_new = str2[:3]\n",
    "str3_new = str3[:6]\n",
    "str4_new = str4[:2]\n",
    "str5_new = str5[:3]\n",
    "\n",
    "print(str1_new)\n",
    "print(str2_new)\n",
    "print(str3_new)\n",
    "print(str4_new)\n",
    "print(str5_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4c9d34f4e783>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# No. Same logic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# No. Same logic\n",
    "s[-200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ We can specify a \"step\" size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2] Try these for yourself, then experiment with different step values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pto'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'otP'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty = 'Monty Python'\n",
    "monty[6:11:2]\n",
    "monty[10:5:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nohtyP ytnoM'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goes backwards starting at last index\n",
    "monty[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Describe the class of strings matched by the following regular expressions.\n",
    "\n",
    "a.[a-zA-Z]+\n",
    "\n",
    "b.[A-Z][a-z]*\n",
    "\n",
    "c.p[aeiou]{,2}t\n",
    "\n",
    "d.\\d+(\\.\\d+)?\n",
    "\n",
    "e.([^aeiou][aeiou][^aeiou])*\n",
    "\n",
    "f.\\w+|[^\\w\\s]+\n",
    "\n",
    "Test your answers using nltk.re_show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{bnSFstput}334{dfd}34{o}49{f}78{j}8\n",
      "bn{S}{Fstput}334dfd34o49f78j8\n",
      "bnSFst{put}334dfd34o49f78j8\n",
      "bnSFstput{334}dfd{34o49}f{78j8}\n",
      "{}b{}n{}S{}F{}s{}t{put}3{}3{}4{}d{}f{}d{}3{4o4}9{}f{}7{}8{}j{}8{}\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "multiple repeat at position 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42528c01217a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#one or more occurrence of a disjunction between an alphanumeric character and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#whitespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mre_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\w+|[^\\w\\s]+*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bnSFstput334dfd34o49f78j8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\util.py\u001b[0m in \u001b[0;36mre_show\u001b[1;34m(regexp, string, left, right)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \"\"\"\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mr\"\\g<0>\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;34m\"Compile a regular expression pattern, returning a pattern object.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(str, flags, pattern)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[1;32m--> 416\u001b[1;33m                            not nested and not items))\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise source.error(\"multiple repeat\",\n\u001b[1;32m--> 619\u001b[1;33m                                    source.tell() - here + len(this))\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                 \u001b[0msubpattern\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mMIN_REPEAT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: multiple repeat at position 12"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# a = one or more occurrences of alphabetical characters (words)\n",
    "nltk.re_show('[a-zA-Z]+', 'bnSFstput334dfd34o49f78j8')\n",
    "\n",
    "# b = capital letter followed by zero or more occurrence of lowercase letters\n",
    "nltk.re_show('[A-Z][a-z]*', 'bnSFstput334dfd34o49f78j8')\n",
    "\n",
    "# c = letter 'p', followed by up to 2 vowels, followed byt letter 't'\n",
    "nltk.re_show('p[aeiou]{,2}t', 'bnSFstput334dfd34o49f78j8')\n",
    "\n",
    "# d = one or more occurrence of a digit, followed by opitional one or more\n",
    "#ocurrence of a digit preceeded by any character\n",
    "nltk.re_show('\\d+(.\\d+)?', 'bnSFstput334dfd34o49f78j8')\n",
    "\n",
    "# e = zero or more occurrences of non-lower case vowel, followed by a \n",
    "#lower case vowel, followed by a non-lower case vowel\n",
    "nltk.re_show('([^aeiou][aeiou][^aeiou])*', 'bnSFstput334dfd34o49f78j8')\n",
    "\n",
    "# f = one or more occurrence of a alphanumeric character XOR exlusion of\n",
    "#one or more occurrence of a disjunction between an alphanumeric character and\n",
    "#whitespace\n",
    "nltk.re_show('\\w+|[^\\w\\s]+*', 'bnSFstput334dfd34o49f78j8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Write regular expressions to match the following classes of strings:\n",
    "\n",
    "a.A single determiner (assume that a, an, and the are the only determiners).\n",
    "\n",
    "b.An arithmetic expression using integers, addition, and multiplication, such as 2*3+8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'an', 'a', 'and'}\n",
      "['33+5=38', '3*8=24']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "\n",
    "list_findings1 = re.findall(r'\\b(a|an|and)\\b', text)\n",
    "print(set(list_findings1))\n",
    "\n",
    "list_findings2 = re.findall(r'\\b(?:\\d+[+*=])+\\d+\\b', 'this is a test to find equation 33+5=38 and 3*8=24')\n",
    "print(list_findings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then  request.urlopen('http://nltk.org/').read().decode('utf8') to access the contents of the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              Natural Language Toolkit &#8212; NLTK 3.4 documentation                                                         NLTK 3.4 documentation                  next |          modules |          index                                                                                       Natural Language Toolkit¶NLTK is a leading platform for building Python programs to work with human language data.It provides easy-to-use interfaces to over 50 corpora and lexicalresources such as WordNet,along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,wrappers for industrial-strength NLP libraries,and an active discussion forum.Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”and “an amazing library to play with natural language.”Natural Language Processing with Python provides a practicalintroduction to programming for language processing.Written by the creators of NLTK, it guides the reader through the fundamentalsof writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,and more.The online version of the book has been been updated for Python 3 and NLTK 3.(The original Python 2 version is still available at http://nltk.org/book_1ed.)Some simple things you can do with NLTK¶Tokenize and tag some text:&gt;&gt;&gt; import nltk&gt;&gt;&gt; sentence = &quot;&quot;&quot;At eight o&#39;clock on Thursday morning... Arthur didn&#39;t feel very good.&quot;&quot;&quot;&gt;&gt;&gt; tokens = nltk.word_tokenize(sentence)&gt;&gt;&gt; tokens[&#39;At&#39;, &#39;eight&#39;, &quot;o&#39;clock&quot;, &#39;on&#39;, &#39;Thursday&#39;, &#39;morning&#39;,&#39;Arthur&#39;, &#39;did&#39;, &quot;n&#39;t&quot;, &#39;feel&#39;, &#39;very&#39;, &#39;good&#39;, &#39;.&#39;]&gt;&gt;&gt; tagged = nltk.pos_tag(tokens)&gt;&gt;&gt; tagged[0:6][(&#39;At&#39;, &#39;IN&#39;), (&#39;eight&#39;, &#39;CD&#39;), (&quot;o&#39;clock&quot;, &#39;JJ&#39;), (&#39;on&#39;, &#39;IN&#39;),(&#39;Thursday&#39;, &#39;NNP&#39;), (&#39;morning&#39;, &#39;NN&#39;)]Identify named entities:&gt;&gt;&gt; entities = nltk.chunk.ne_chunk(tagged)&gt;&gt;&gt; entitiesTree(&#39;S&#39;, [(&#39;At&#39;, &#39;IN&#39;), (&#39;eight&#39;, &#39;CD&#39;), (&quot;o&#39;clock&quot;, &#39;JJ&#39;),           (&#39;on&#39;, &#39;IN&#39;), (&#39;Thursday&#39;, &#39;NNP&#39;), (&#39;morning&#39;, &#39;NN&#39;),       Tree(&#39;PERSON&#39;, [(&#39;Arthur&#39;, &#39;NNP&#39;)]),           (&#39;did&#39;, &#39;VBD&#39;), (&quot;n&#39;t&quot;, &#39;RB&#39;), (&#39;feel&#39;, &#39;VB&#39;),           (&#39;very&#39;, &#39;RB&#39;), (&#39;good&#39;, &#39;JJ&#39;), (&#39;.&#39;, &#39;.&#39;)])Display a parse tree:&gt;&gt;&gt; from nltk.corpus import treebank&gt;&gt;&gt; t = treebank.parsed_sents(&#39;wsj_0001.mrg&#39;)[0]&gt;&gt;&gt; t.draw()NB. If you publish work that uses NLTK, please cite the NLTK book asfollows:Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python.  O’Reilly Media Inc.Next Steps¶sign up for release announcementsjoin in the discussionContents¶NLTK NewsInstalling NLTKInstalling NLTK DataContribute to NLTKFAQWikiAPIHOWTOIndexModule IndexSearch Page                                                  Table Of Contents          NLTK NewsInstalling NLTKInstalling NLTK DataContribute to NLTKFAQWikiAPIHOWTO                      Search                                                                                                                                                                    next |            modules |            index                                                Show Source                                                &#169; Copyright 2019, NLTK Project.      Last updated on Nov 17, 2018.      Created using Sphinx 1.7.9.                                '"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def removeHTML(text):\n",
    "    #nltk.re_show(r'<.*>|\\n', text)\n",
    "    text = re.sub(r'<[^>]*>|\\n','', text)\n",
    "    return text\n",
    "\n",
    "    \n",
    "raw = request.urlopen('http://nltk.org/').read().decode('utf8') \n",
    "removeHTML(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "\n",
    "a.Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multi-line regular expression, with inline comments, using the verbose flag (?x).\n",
    "\n",
    "b.Use nltk.regexp_tokenize() to create a tokenizer that tokenizes the following kinds of expression: monetary amounts; dates; names of people and organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-', '.', ':'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{('', 'Stalin', '', ''),\n",
       " ('', 'Advanced', '', ''),\n",
       " ('28/10/2019', '', '', ''),\n",
       " ('', 'Extracting', '', ''),\n",
       " ('15/04/2019', '', '', ''),\n",
       " ('', 'Master', '', ''),\n",
       " ('', 'Have', '', ''),\n",
       " ('', 'General', '', ''),\n",
       " ('', 'Instrumental', '', ''),\n",
       " ('01/04/2019', '', '', ''),\n",
       " ('', 'Preface', '', ''),\n",
       " ('13/10/2019', '', '', ''),\n",
       " ('', 'Sparsity', '', ''),\n",
       " ('25/11/2019', '', '', ''),\n",
       " ('', 'At', '', ''),\n",
       " ('', '', '47', ''),\n",
       " ('', 'Liev', '', ''),\n",
       " ('', 'Narrativas', '', ''),\n",
       " ('27/01/2019', '', '', ''),\n",
       " ('07/12/2019', '', '', ''),\n",
       " ('', 'Dative', '', ''),\n",
       " ('04/01/2019', '', '', ''),\n",
       " ('24/12/2019', '', '', ''),\n",
       " ('', 'Raw', '', ''),\n",
       " ('18/06/2019', '', '', ''),\n",
       " ('', 'Fant', '', ''),\n",
       " ('', 'Motor', '', ''),\n",
       " ('', '', '12', ''),\n",
       " ('13/01/2019', '', '', ''),\n",
       " ('', 'Genitive', '', ''),\n",
       " ('', 'Enables', '', ''),\n",
       " ('', 'Model', '', ''),\n",
       " ('12/03/2019', '', '', ''),\n",
       " ('', 'Guerra', '', ''),\n",
       " ('', '', '19', ''),\n",
       " ('', 'Hyperbolic', '', ''),\n",
       " ('21/06/2019', '', '', ''),\n",
       " ('', 'Variations', '', ''),\n",
       " ('', 'Orientation', '', ''),\n",
       " ('', 'Guest', '', ''),\n",
       " ('15/12/2019', '', '', ''),\n",
       " ('', 'German', '', ''),\n",
       " ('', 'Embeddings', '', ''),\n",
       " ('26/05/2019', '', '', ''),\n",
       " ('16/12/2018', '', '', ''),\n",
       " ('19/07/2019', '', '', ''),\n",
       " ('', 'Test', '', ''),\n",
       " ('20/03/2019', '', '', ''),\n",
       " ('', 'What', '', ''),\n",
       " ('', 'Normal', '', ''),\n",
       " ('', 'Course', '', ''),\n",
       " ('', 'Gettting', '', ''),\n",
       " ('17/02/2019', '', '', ''),\n",
       " ('', 'Russian', '', ''),\n",
       " ('', '', '40', ''),\n",
       " ('', 'Games', '', ''),\n",
       " ('', 'Paz', '', ''),\n",
       " ('', 'Half', '', ''),\n",
       " ('02/05/2019', '', '', ''),\n",
       " ('13/06/2019', '', '', ''),\n",
       " ('', 'Affect', '', ''),\n",
       " ('', 'Architectures', '', ''),\n",
       " ('', 'Compet', '', ''),\n",
       " ('', 'Lexical', '', ''),\n",
       " ('', 'Medidas', '', ''),\n",
       " ('01/12/2018', '', '', ''),\n",
       " ('', 'Problems', '', ''),\n",
       " ('', 'Floor', '', ''),\n",
       " ('', 'Especiais', '', ''),\n",
       " ('04/10/2019', '', '', ''),\n",
       " ('15/06/2019', '', '', ''),\n",
       " ('', '', '46', ''),\n",
       " ('28/12/2018', '', '', ''),\n",
       " ('30/05/2019', '', '', ''),\n",
       " ('', 'Regression', '', ''),\n",
       " ('', 'Linguagem', '', ''),\n",
       " ('16/03/2019', '', '', ''),\n",
       " ('', 'Topographie', '', ''),\n",
       " ('', 'Miscellaneous', '', ''),\n",
       " ('', 'Things', '', ''),\n",
       " ('', 'Tencent', '', ''),\n",
       " ('', 'Uncertainty', '', ''),\n",
       " ('', 'Reducing', '', ''),\n",
       " ('', '', '10', ''),\n",
       " ('', 'Aspect', '', ''),\n",
       " ('28/03/2019', '', '', ''),\n",
       " ('31/08/2019', '', '', ''),\n",
       " ('', 'Philosofical', '', ''),\n",
       " ('', '', '1', ''),\n",
       " ('27/06/2019', '', '', ''),\n",
       " ('24/12/2018', '', '', ''),\n",
       " ('09/08/2019', '', '', ''),\n",
       " ('24/05/2019', '', '', ''),\n",
       " ('', 'Prefixes', '', ''),\n",
       " ('', 'Fun', '', ''),\n",
       " ('', 'Obligation', '', ''),\n",
       " ('', '', '25', ''),\n",
       " ('', 'Sandel', '', ''),\n",
       " ('28/08/2019', '', '', ''),\n",
       " ('', 'Yuval', '', ''),\n",
       " ('02/07/2019', '', '', ''),\n",
       " ('16/06/2019', '', '', ''),\n",
       " ('', 'Recognition', '', ''),\n",
       " ('', 'Towards', '', ''),\n",
       " ('18/01/2019', '', '', ''),\n",
       " ('', 'Politness', '', ''),\n",
       " ('', 'Crash', '', ''),\n",
       " ('31/10/2019', '', '', ''),\n",
       " ('', 'Least', '', ''),\n",
       " ('', 'Comparative', '', ''),\n",
       " ('', 'Prinz', '', ''),\n",
       " ('27/09/2019', '', '', ''),\n",
       " ('', '', '7', ''),\n",
       " ('11/08/2019', '', '', ''),\n",
       " ('10/04/2019', '', '', ''),\n",
       " ('21/09/2019', '', '', ''),\n",
       " ('', 'Reasoning', '', ''),\n",
       " ('', 'Modeling', '', ''),\n",
       " ('', 'Plurals', '', ''),\n",
       " ('16/02/2019', '', '', ''),\n",
       " ('28/11/2019', '', '', ''),\n",
       " ('', 'Accelerating', '', ''),\n",
       " ('', 'Statistics', '', ''),\n",
       " ('', 'Science', '', ''),\n",
       " ('07/04/2019', '', '', ''),\n",
       " ('', '', '6', ''),\n",
       " ('', 'Accusative', '', ''),\n",
       " ('', 'Group', '', ''),\n",
       " ('09/09/2019', '', '', ''),\n",
       " ('', '', '15', ''),\n",
       " ('13/09/2019', '', '', ''),\n",
       " ('', 'Spaces', '', ''),\n",
       " ('', 'Ordinal', '', ''),\n",
       " ('', 'Saint', '', ''),\n",
       " ('', 'Books', '', ''),\n",
       " ('', 'Differentiation', '', ''),\n",
       " ('', 'Bayes', '', ''),\n",
       " ('', 'Systems', '', ''),\n",
       " ('29/03/2019', '', '', ''),\n",
       " ('19/08/2019', '', '', ''),\n",
       " ('', 'Interfaces', '', ''),\n",
       " ('29/09/2019', '', '', ''),\n",
       " ('', 'Exupery', '', ''),\n",
       " ('25/12/2018', '', '', ''),\n",
       " ('02/08/2019', '', '', ''),\n",
       " ('', 'Form', '', ''),\n",
       " ('', 'End', '', ''),\n",
       " ('14/07/2019', '', '', ''),\n",
       " ('', 'Line', '', ''),\n",
       " ('', 'Adverbs', '', ''),\n",
       " ('', 'Describing', '', ''),\n",
       " ('26/12/2019', '', '', ''),\n",
       " ('04/09/2019', '', '', ''),\n",
       " ('21/04/2019', '', '', ''),\n",
       " ('09/12/2018', '', '', ''),\n",
       " ('', 'Sem', '', ''),\n",
       " ('', 'Text', '', ''),\n",
       " ('29/07/2019', '', '', ''),\n",
       " ('', 'Solaiman', '', ''),\n",
       " ('', 'Humana', '', ''),\n",
       " ('', 'Mathematical', '', ''),\n",
       " ('', '', '29', ''),\n",
       " ('', 'Complete', '', ''),\n",
       " ('', 'Computational', '', ''),\n",
       " ('', 'Tarkovsky', '', ''),\n",
       " ('18/02/2019', '', '', ''),\n",
       " ('', 'Fourier', '', ''),\n",
       " ('25/06/2019', '', '', ''),\n",
       " ('', 'Communication', '', ''),\n",
       " ('', 'Movemtnts', '', ''),\n",
       " ('23/12/2018', '', '', ''),\n",
       " ('', 'The', '', ''),\n",
       " ('', 'Resumo', '', ''),\n",
       " ('01/06/2019', '', '', ''),\n",
       " ('', 'Artificial', '', ''),\n",
       " ('', 'Integrals', '', ''),\n",
       " ('23/06/2019', '', '', ''),\n",
       " ('17/05/2019', '', '', ''),\n",
       " ('11/09/2019', '', '', ''),\n",
       " ('19/12/2018', '', '', ''),\n",
       " ('24/07/2019', '', '', ''),\n",
       " ('29/12/2018', '', '', ''),\n",
       " ('', 'Protocol', '', ''),\n",
       " ('', 'Deathly', '', ''),\n",
       " ('', 'Support', '', ''),\n",
       " ('', 'Fon', '', ''),\n",
       " ('', 'Date', '', ''),\n",
       " ('', 'Limits', '', ''),\n",
       " ('', 'Topics', '', ''),\n",
       " ('14/10/2019', '', '', ''),\n",
       " ('09/03/2019', '', '', ''),\n",
       " ('', 'Diminutives', '', ''),\n",
       " ('', 'Signos', '', ''),\n",
       " ('13/07/2019', '', '', ''),\n",
       " ('19/02/2019', '', '', ''),\n",
       " ('24/11/2019', '', '', ''),\n",
       " ('30/12/2019', '', '', ''),\n",
       " ('', 'Prework', '', ''),\n",
       " ('12/10/2019', '', '', ''),\n",
       " ('25/01/2019', '', '', ''),\n",
       " ('23/11/2019', '', '', ''),\n",
       " ('', 'Discourse', '', ''),\n",
       " ('', 'Induces', '', ''),\n",
       " ('04/08/2019', '', '', ''),\n",
       " ('17/03/2019', '', '', ''),\n",
       " ('', 'Task', '', ''),\n",
       " ('26/04/2019', '', '', ''),\n",
       " ('08/03/2019', '', '', ''),\n",
       " ('', 'Programs', '', ''),\n",
       " ('', 'Planning', '', ''),\n",
       " ('31/05/2019', '', '', ''),\n",
       " ('', 'Verbal', '', ''),\n",
       " ('', 'Fernando', '', ''),\n",
       " ('22/09/2019', '', '', ''),\n",
       " ('27/04/2019', '', '', ''),\n",
       " ('15/12/2018', '', '', ''),\n",
       " ('', 'Negation', '', ''),\n",
       " ('', 'Regularisation', '', ''),\n",
       " ('', 'Proper', '', ''),\n",
       " ('', 'Simple', '', ''),\n",
       " ('', 'Means', '', ''),\n",
       " ('', 'Information', '', ''),\n",
       " ('', 'Abbreviations', '', ''),\n",
       " ('', 'Language', '', ''),\n",
       " ('', 'Integral', '', ''),\n",
       " ('', 'Injuries', '', ''),\n",
       " ('23/05/2019', '', '', ''),\n",
       " ('11/03/2019', '', '', ''),\n",
       " ('', 'Minimax', '', ''),\n",
       " ('', 'Discurso', '', ''),\n",
       " ('', '', '0', ''),\n",
       " ('', 'Linguistic', '', ''),\n",
       " ('', 'Sentence', '', ''),\n",
       " ('14/04/2019', '', '', ''),\n",
       " ('11/07/2019', '', '', ''),\n",
       " ('', '', '37', ''),\n",
       " ('', 'Monkeys', '', ''),\n",
       " ('', 'Meets', '', ''),\n",
       " ('', 'Device', '', ''),\n",
       " ('', 'Facing', '', ''),\n",
       " ('', '', '52', ''),\n",
       " ('', 'Perspective', '', ''),\n",
       " ('09/04/2019', '', '', ''),\n",
       " ('', '', '57', ''),\n",
       " ('21/03/2019', '', '', ''),\n",
       " ('16/07/2019', '', '', ''),\n",
       " ('', 'Equations', '', ''),\n",
       " ('', 'Dialog', '', ''),\n",
       " ('18/10/2019', '', '', ''),\n",
       " ('', 'Neuroprotheses', '', ''),\n",
       " ('28/04/2019', '', '', ''),\n",
       " ('29/12/2019', '', '', ''),\n",
       " ('', 'Linking', '', ''),\n",
       " ('', 'Connotation', '', ''),\n",
       " ('26/12/2018', '', '', ''),\n",
       " ('', 'Sentiment', '', ''),\n",
       " ('10/12/2018', '', '', ''),\n",
       " ('05/04/2019', '', '', ''),\n",
       " ('', 'Thinking', '', ''),\n",
       " ('', 'Letters', '', ''),\n",
       " ('', 'Atients', '', ''),\n",
       " ('', 'Justica', '', ''),\n",
       " ('23/09/2019', '', '', ''),\n",
       " ('29/08/2019', '', '', ''),\n",
       " ('', 'Expressions', '', ''),\n",
       " ('31/03/2019', '', '', ''),\n",
       " ('27/07/2019', '', '', ''),\n",
       " ('02/04/2019', '', '', ''),\n",
       " ('08/07/2019', '', '', ''),\n",
       " ('', 'Verbs', '', ''),\n",
       " ('12/09/2019', '', '', ''),\n",
       " ('', 'Take', '', ''),\n",
       " ('17/04/2019', '', '', ''),\n",
       " ('', '', '33', ''),\n",
       " ('', 'Introducao', '', ''),\n",
       " ('', 'Examples', '', ''),\n",
       " ('', 'Basics', '', ''),\n",
       " ('', 'Possession', '', ''),\n",
       " ('', 'Search', '', ''),\n",
       " ('20/12/2018', '', '', ''),\n",
       " ('30/10/2019', '', '', ''),\n",
       " ('', 'Uso', '', ''),\n",
       " ('', 'Boosting', '', ''),\n",
       " ('', '', '1999', ''),\n",
       " ('', 'Recorded', '', ''),\n",
       " ('', '', '49', ''),\n",
       " ('14/11/2019', '', '', ''),\n",
       " ('', 'Sequence', '', ''),\n",
       " ('', 'Fonologia', '', ''),\n",
       " ('', 'Udemy', '', ''),\n",
       " ('12/11/2019', '', '', ''),\n",
       " ('', 'Near', '', ''),\n",
       " ('', 'Functions', '', ''),\n",
       " ('', 'Explorando', '', ''),\n",
       " ('02/03/2019', '', '', ''),\n",
       " ('', 'Racionais', '', ''),\n",
       " ('', '', '16', ''),\n",
       " ('', 'Questions', '', ''),\n",
       " ('', '', '30', ''),\n",
       " ('18/11/2019', '', '', ''),\n",
       " ('', 'Flow', '', ''),\n",
       " ('', 'Answering', '', ''),\n",
       " ('17/11/2019', '', '', ''),\n",
       " ('', 'Ordinary', '', ''),\n",
       " ('', 'Optimal', '', ''),\n",
       " ('02/12/2018', '', '', ''),\n",
       " ('', 'Mudan', '', ''),\n",
       " ('', 'Future', '', ''),\n",
       " ('', 'Cord', '', ''),\n",
       " ('', 'Aquisi', '', ''),\n",
       " ('', 'Brain', '', ''),\n",
       " ('02/02/2019', '', '', ''),\n",
       " ('', '', '27', ''),\n",
       " ('', 'Agents', '', ''),\n",
       " ('', 'Variables', '', ''),\n",
       " ('', 'Parsing', '', ''),\n",
       " ('', 'Trainer', '', ''),\n",
       " ('24/06/2019', '', '', ''),\n",
       " ('09/01/2019', '', '', ''),\n",
       " ('', 'Nick', '', ''),\n",
       " ('31/12/2018', '', '', ''),\n",
       " ('01/10/2019', '', '', ''),\n",
       " ('', 'Cortex', '', ''),\n",
       " ('', 'Superintelligence', '', ''),\n",
       " ('', 'Faster', '', ''),\n",
       " ('', 'Matrices', '', ''),\n",
       " ('', 'Patients', '', ''),\n",
       " ('20/05/2019', '', '', ''),\n",
       " ('', '', '28', ''),\n",
       " ('15/07/2019', '', '', ''),\n",
       " ('', 'Preliminary', '', ''),\n",
       " ('', 'Differential', '', ''),\n",
       " ('', 'Michael', '', ''),\n",
       " ('', 'Neuroscience', '', ''),\n",
       " ('', 'Intelligency', '', ''),\n",
       " ('01/05/2019', '', '', ''),\n",
       " ('', 'Operators', '', ''),\n",
       " ('', 'Milan', '', ''),\n",
       " ('', 'Terreur', '', ''),\n",
       " ('', 'Dia', '', ''),\n",
       " ('', 'Feedback', '', ''),\n",
       " ('', 'Sentences', '', ''),\n",
       " ('29/01/2019', '', '', ''),\n",
       " ('', 'Book', '', ''),\n",
       " ('', 'Translation', '', ''),\n",
       " ('07/07/2019', '', '', ''),\n",
       " ('26/10/2019', '', '', ''),\n",
       " ('', 'Types', '', ''),\n",
       " ('', '', '18', ''),\n",
       " ('27/11/2019', '', '', ''),\n",
       " ('', 'Validation', '', ''),\n",
       " ('17/07/2019', '', '', ''),\n",
       " ('', 'Personal', '', ''),\n",
       " ('', 'Corpora', '', ''),\n",
       " ('', 'Duas', '', ''),\n",
       " ('', 'Grams', '', ''),\n",
       " ('', 'Names', '', ''),\n",
       " ('', '', '32', ''),\n",
       " ('', '', '6.5191', '.5191'),\n",
       " ('', 'Steps', '', ''),\n",
       " ('', 'Exercises', '', ''),\n",
       " ('', 'English', '', ''),\n",
       " ('', 'Places', '', ''),\n",
       " ('23/03/2019', '', '', ''),\n",
       " ('', '', '2006', ''),\n",
       " ('17/08/2019', '', '', ''),\n",
       " ('', 'Perception', '', ''),\n",
       " ('', '', '34', ''),\n",
       " ('31/01/2019', '', '', ''),\n",
       " ('', 'Harari', '', ''),\n",
       " ('22/12/2018', '', '', ''),\n",
       " ('11/04/2019', '', '', ''),\n",
       " ('', 'Numerical', '', ''),\n",
       " ('', 'Semantics', '', ''),\n",
       " ('25/08/2019', '', '', ''),\n",
       " ('03/01/2019', '', '', ''),\n",
       " ('', 'Dynamic', '', ''),\n",
       " ('', 'Tactile', '', ''),\n",
       " ('', '', '31', ''),\n",
       " ('', 'Robotics', '', ''),\n",
       " ('', 'Arm', '', ''),\n",
       " ('25/12/2019', '', '', ''),\n",
       " ('', 'Models', '', ''),\n",
       " ('', '', '17', ''),\n",
       " ('', 'Estudos', '', ''),\n",
       " ('', 'Structured', '', ''),\n",
       " ('', '', '24', ''),\n",
       " ('', '', '51', ''),\n",
       " ('04/11/2019', '', '', ''),\n",
       " ('', '', '2010', ''),\n",
       " ('', 'Punctuation', '', ''),\n",
       " ('', 'Exerc', '', ''),\n",
       " ('', 'Year', '', ''),\n",
       " ('13/12/2019', '', '', ''),\n",
       " ('21/05/2019', '', '', ''),\n",
       " ('', 'Series', '', ''),\n",
       " ('', 'Principles', '', ''),\n",
       " ('20/07/2019', '', '', ''),\n",
       " ('', 'Legs', '', ''),\n",
       " ('', 'Texto', '', ''),\n",
       " ('', 'User', '', ''),\n",
       " ('', 'Estima', '', ''),\n",
       " ('', 'Building', '', ''),\n",
       " ('07/01/2019', '', '', ''),\n",
       " ('19/03/2019', '', '', ''),\n",
       " ('16/05/2019', '', '', ''),\n",
       " ('21/01/2019', '', '', ''),\n",
       " ('', 'Sobrevivendo', '', ''),\n",
       " ('07/05/2019', '', '', ''),\n",
       " ('07/08/2019', '', '', ''),\n",
       " ('04/03/2019', '', '', ''),\n",
       " ('', 'Synthesis', '', ''),\n",
       " ('', 'Deep', '', ''),\n",
       " ('', 'Descending', '', ''),\n",
       " ('', 'Bostrom', '', ''),\n",
       " ('', 'Algebra', '', ''),\n",
       " ('', 'Fire', '', ''),\n",
       " ('10/09/2019', '', '', ''),\n",
       " ('', 'Prerequisites', '', ''),\n",
       " ('', 'Surface', '', ''),\n",
       " ('', 'More', '', ''),\n",
       " ('26/07/2019', '', '', ''),\n",
       " ('', 'Quiz', '', ''),\n",
       " ('', 'Morte', '', ''),\n",
       " ('', 'Blood', '', ''),\n",
       " ('30/03/2019', '', '', ''),\n",
       " ('', 'Generalization', '', ''),\n",
       " ('', 'Short', '', ''),\n",
       " ('20/12/2019', '', '', ''),\n",
       " ('', '', '6.034', '.034'),\n",
       " ('', '', '9', ''),\n",
       " ('21/07/2019', '', '', ''),\n",
       " ('23/12/2019', '', '', ''),\n",
       " ('', '', '61', ''),\n",
       " ('', 'Intelligent', '', ''),\n",
       " ('', 'Going', '', ''),\n",
       " ('', 'Word', '', ''),\n",
       " ('', 'Managing', '', ''),\n",
       " ('', 'Chatbots', '', ''),\n",
       " ('19/11/2019', '', '', ''),\n",
       " ('12/06/2019', '', '', ''),\n",
       " ('', 'Tensorflow', '', ''),\n",
       " ('10/11/2019', '', '', ''),\n",
       " ('', 'How', '', ''),\n",
       " ('15/05/2019', '', '', ''),\n",
       " ('', 'Chamber', '', ''),\n",
       " ('', 'Abordagem', '', ''),\n",
       " ('28/09/2019', '', '', ''),\n",
       " ('22/12/2019', '', '', ''),\n",
       " ('', 'Crosses', '', ''),\n",
       " ('05/02/2019', '', '', ''),\n",
       " ('', 'Feature', '', ''),\n",
       " ('', '', '48', ''),\n",
       " ('06/10/2019', '', '', ''),\n",
       " ('19/09/2019', '', '', ''),\n",
       " ('19/10/2019', '', '', ''),\n",
       " ('29/11/2019', '', '', ''),\n",
       " ('', 'Using', '', ''),\n",
       " ('12/01/2019', '', '', ''),\n",
       " ('', 'Categorizing', '', ''),\n",
       " ('13/04/2019', '', '', ''),\n",
       " ('', 'Quantum', '', ''),\n",
       " ('21/12/2019', '', '', ''),\n",
       " ('', 'Intelligence', '', ''),\n",
       " ('08/12/2018', '', '', ''),\n",
       " ('27/02/2019', '', '', ''),\n",
       " ('', 'Dados', '', ''),\n",
       " ('', '', '36', ''),\n",
       " ('', 'Paper', '', ''),\n",
       " ('', 'Time', '', ''),\n",
       " ('', 'Eigenfunction', '', ''),\n",
       " ('29/06/2019', '', '', ''),\n",
       " ('', 'Lingu', '', ''),\n",
       " ('', 'Neurons', '', ''),\n",
       " ('', 'Neurological', '', ''),\n",
       " ('06/01/2019', '', '', ''),\n",
       " ('05/10/2019', '', '', ''),\n",
       " ('', 'Restriction', '', ''),\n",
       " ('', 'Formal', '', ''),\n",
       " ('', 'Alpha', '', ''),\n",
       " ('', 'Interface', '', ''),\n",
       " ('', 'Indefinite', '', ''),\n",
       " ('', 'Quantifying', '', ''),\n",
       " ('', 'Tensor', '', ''),\n",
       " ('25/05/2019', '', '', ''),\n",
       " ('', 'Alderman', '', ''),\n",
       " ('04/12/2019', '', '', ''),\n",
       " ('', 'Syntactic', '', ''),\n",
       " ('', 'Cont', '', ''),\n",
       " ('', 'Statistical', '', ''),\n",
       " ('', 'Off', '', ''),\n",
       " ('', 'Encoders', '', ''),\n",
       " ('', 'Resources', '', ''),\n",
       " ('29/04/2019', '', '', ''),\n",
       " ('05/12/2018', '', '', ''),\n",
       " ('', 'Classic', '', ''),\n",
       " ('', 'New', '', ''),\n",
       " ('', 'Neuroheabilitation', '', ''),\n",
       " ('', 'Partial', '', ''),\n",
       " ('04/07/2019', '', '', ''),\n",
       " ('', 'Introdu', '', ''),\n",
       " ('12/07/2019', '', '', ''),\n",
       " ('16/08/2019', '', '', ''),\n",
       " ('', '', '2013', ''),\n",
       " ('15/01/2019', '', '', ''),\n",
       " ('', '', '55', ''),\n",
       " ('05/11/2019', '', '', ''),\n",
       " ('', 'Sunday', '', ''),\n",
       " ('22/11/2019', '', '', ''),\n",
       " ('', 'Coherence', '', ''),\n",
       " ('06/02/2019', '', '', ''),\n",
       " ('', 'Tensors', '', ''),\n",
       " ('', 'Past', '', ''),\n",
       " ('', 'Vision', '', ''),\n",
       " ('27/03/2019', '', '', ''),\n",
       " ('', 'Volume', '', ''),\n",
       " ('', 'Multiple', '', ''),\n",
       " ('17/01/2019', '', '', ''),\n",
       " ('16/04/2019', '', '', ''),\n",
       " ('30/04/2019', '', '', ''),\n",
       " ('14/05/2019', '', '', ''),\n",
       " ('19/04/2019', '', '', ''),\n",
       " ('', 'Semantic', '', ''),\n",
       " ('20/02/2019', '', '', ''),\n",
       " ('09/06/2019', '', '', ''),\n",
       " ('', 'Regular', '', ''),\n",
       " ('10/10/2019', '', '', ''),\n",
       " ('', 'Complex', '', ''),\n",
       " ('', 'Important', '', ''),\n",
       " ('06/07/2019', '', '', ''),\n",
       " ('', 'Probabilistic', '', ''),\n",
       " ('', 'Doing', '', ''),\n",
       " ('04/05/2019', '', '', ''),\n",
       " ('07/09/2019', '', '', ''),\n",
       " ('', 'Prisoner', '', ''),\n",
       " ('31/07/2019', '', '', ''),\n",
       " ('', '', '35', ''),\n",
       " ('01/11/2019', '', '', ''),\n",
       " ('03/12/2019', '', '', ''),\n",
       " ('', 'First', '', ''),\n",
       " ('', 'Based', '', ''),\n",
       " ('', 'Reducation', '', ''),\n",
       " ('', 'Imperative', '', ''),\n",
       " ('', 'Kleine', '', ''),\n",
       " ('', 'Use', '', ''),\n",
       " ('', 'Adjectives', '', ''),\n",
       " ('', 'Developments', '', ''),\n",
       " ('', 'Suprlatives', '', ''),\n",
       " ('26/03/2019', '', '', ''),\n",
       " ('', '', '2016', ''),\n",
       " ('03/10/2019', '', '', ''),\n",
       " ('', '', '2019', ''),\n",
       " ('', 'Vector', '', ''),\n",
       " ('', 'Setup', '', ''),\n",
       " ('08/09/2019', '', '', ''),\n",
       " ('', 'Writting', '', ''),\n",
       " ('14/12/2019', '', '', ''),\n",
       " ('10/05/2019', '', '', ''),\n",
       " ('19/05/2019', '', '', ''),\n",
       " ('', '', '38', ''),\n",
       " ('27/12/2019', '', '', ''),\n",
       " ('', 'Why', '', ''),\n",
       " ('06/05/2019', '', '', ''),\n",
       " ('', 'Beach', '', ''),\n",
       " ('', 'Participles', '', ''),\n",
       " ('', 'Fiodor', '', ''),\n",
       " ('', 'Paraplegic', '', ''),\n",
       " ('', 'Reflexive', '', ''),\n",
       " ('', 'An', '', ''),\n",
       " ('', 'Azkaban', '', ''),\n",
       " ('', 'Recitaiton', '', ''),\n",
       " ('', 'Mikhail', '', ''),\n",
       " ('24/01/2019', '', '', ''),\n",
       " ('30/11/2019', '', '', ''),\n",
       " ('', 'Peter', '', ''),\n",
       " ('', 'Overview', '', ''),\n",
       " ('', 'Speech', '', ''),\n",
       " ('', 'Frontiers', '', ''),\n",
       " ('', 'Oficial', '', ''),\n",
       " ('', 'Computer', '', ''),\n",
       " ('', 'Role', '', ''),\n",
       " ('', 'Challenge', '', ''),\n",
       " ('07/03/2019', '', '', ''),\n",
       " ('', 'Assimilation', '', ''),\n",
       " ('', 'Engineering', '', ''),\n",
       " ('', 'Question', '', ''),\n",
       " ('', '', '39', ''),\n",
       " ('', 'Prepositional', '', ''),\n",
       " ('16/11/2019', '', '', ''),\n",
       " ('08/11/2019', '', '', ''),\n",
       " ('19/12/2019', '', '', ''),\n",
       " ('14/02/2019', '', '', ''),\n",
       " ('20/01/2019', '', '', ''),\n",
       " ('', '', '13', ''),\n",
       " ('11/01/2019', '', '', ''),\n",
       " ('', 'Mulher', '', ''),\n",
       " ('', 'Estat', '', ''),\n",
       " ('', 'Decisions', '', ''),\n",
       " ('', 'Kundera', '', ''),\n",
       " ('', 'Computing', '', ''),\n",
       " ('', 'Machines', '', ''),\n",
       " ('10/08/2019', '', '', ''),\n",
       " ('', 'Thursday', '', ''),\n",
       " ('', 'Explorat', '', ''),\n",
       " ('', 'Novel', '', ''),\n",
       " ('28/05/2019', '', '', ''),\n",
       " ('', 'Walk', '', ''),\n",
       " ('05/05/2019', '', '', ''),\n",
       " ('', 'Active', '', ''),\n",
       " ('', 'Image', '', ''),\n",
       " ('', 'Pronouns', '', ''),\n",
       " ('', 'Varia', '', ''),\n",
       " ('', 'Inferno', '', ''),\n",
       " ('03/08/2019', '', '', ''),\n",
       " ('01/08/2019', '', '', ''),\n",
       " ('', 'Set', '', ''),\n",
       " ('', 'Entity', '', ''),\n",
       " ('02/10/2019', '', '', ''),\n",
       " ('', 'Aurelie', '', ''),\n",
       " ('22/02/2019', '', '', ''),\n",
       " ('', '', '63', ''),\n",
       " ('', 'Running', '', ''),\n",
       " ('02/01/2019', '', '', ''),\n",
       " ('', 'Trials', '', ''),\n",
       " ('23/01/2019', '', '', ''),\n",
       " ('30/07/2019', '', '', ''),\n",
       " ('01/01/2019', '', '', ''),\n",
       " ('', 'Simultaneously', '', ''),\n",
       " ('', 'Pessoa', '', ''),\n",
       " ('', 'Production', '', ''),\n",
       " ('02/12/2019', '', '', ''),\n",
       " ('', 'Tagging', '', ''),\n",
       " ('30/01/2019', '', '', ''),\n",
       " ('', 'Stress', '', ''),\n",
       " ('18/03/2019', '', '', ''),\n",
       " ('', 'Impersonal', '', ''),\n",
       " ('08/08/2019', '', '', ''),\n",
       " ('', 'Secrets', '', ''),\n",
       " ('', 'Hallows', '', ''),\n",
       " ('', 'Probabilidade', '', ''),\n",
       " ('', 'Formulas', '', ''),\n",
       " ('', 'Naomi', '', ''),\n",
       " ('', 'Aleat', '', ''),\n",
       " ('13/03/2019', '', '', ''),\n",
       " ('08/05/2019', '', '', ''),\n",
       " ('', 'Extraction', '', ''),\n",
       " ('22/08/2019', '', '', ''),\n",
       " ('', 'Bidimensionais', '', ''),\n",
       " ('07/11/2019', '', '', ''),\n",
       " ('13/11/2019', '', '', ''),\n",
       " ('18/12/2019', '', '', ''),\n",
       " ('', '', '21', ''),\n",
       " ('', 'No', '', ''),\n",
       " ('', 'Stauffer', '', ''),\n",
       " ('', 'Wednesday', '', ''),\n",
       " ('15/11/2019', '', '', ''),\n",
       " ('', 'Meio', '', ''),\n",
       " ('', 'Cs', '', ''),\n",
       " ('17/12/2019', '', '', ''),\n",
       " ('', 'Machinery', '', ''),\n",
       " ('', 'Andrey', '', ''),\n",
       " ('', '', '41', ''),\n",
       " ('28/07/2019', '', '', ''),\n",
       " ('', 'Bookish', '', ''),\n",
       " ('02/06/2019', '', '', ''),\n",
       " ('', 'Bimanual', '', ''),\n",
       " ('08/06/2019', '', '', ''),\n",
       " ('', 'Knowledge', '', ''),\n",
       " ('26/01/2019', '', '', ''),\n",
       " ('', 'John', '', ''),\n",
       " ('', 'Constraints', '', ''),\n",
       " ('', 'Tenses', '', ''),\n",
       " ('03/02/2019', '', '', ''),\n",
       " ('', 'Completos', '', ''),\n",
       " ('04/06/2019', '', '', ''),\n",
       " ('20/10/2019', '', '', ''),\n",
       " ('', 'Static', '', ''),\n",
       " ('12/04/2019', '', '', ''),\n",
       " ('12/05/2019', '', '', ''),\n",
       " ('17/09/2019', '', '', ''),\n",
       " ('', 'Vari', '', ''),\n",
       " ('', 'Nazista', '', ''),\n",
       " ('25/09/2019', '', '', ''),\n",
       " ('21/08/2019', '', '', ''),\n",
       " ('24/10/2019', '', '', ''),\n",
       " ('16/12/2019', '', '', ''),\n",
       " ('24/09/2019', '', '', ''),\n",
       " ('15/10/2019', '', '', ''),\n",
       " ('', 'Potter', '', ''),\n",
       " ('11/02/2019', '', '', ''),\n",
       " ('06/08/2019', '', '', ''),\n",
       " ('19/06/2019', '', '', ''),\n",
       " ('22/01/2019', '', '', ''),\n",
       " ('25/04/2019', '', '', ''),\n",
       " ('', 'Misses', '', ''),\n",
       " ('12/12/2018', '', '', ''),\n",
       " ('', 'Bringing', '', ''),\n",
       " ('02/09/2019', '', '', ''),\n",
       " ('', 'Classification', '', ''),\n",
       " ('', 'Other', '', ''),\n",
       " ('', 'Networks', '', ''),\n",
       " ('', 'Order', '', ''),\n",
       " ('28/02/2019', '', '', ''),\n",
       " ('', 'Adversarial', '', ''),\n",
       " ('', 'Natural', '', ''),\n",
       " ('06/12/2018', '', '', ''),\n",
       " ('08/01/2019', '', '', ''),\n",
       " ('', 'Monday', '', ''),\n",
       " ('', '', '6.096', '.096'),\n",
       " ('', 'Clinical', '', ''),\n",
       " ('22/10/2019', '', '', ''),\n",
       " ('', 'Numbers', '', ''),\n",
       " ('', 'Society', '', ''),\n",
       " ('', 'Modes', '', ''),\n",
       " ('05/08/2019', '', '', ''),\n",
       " ('', 'Logistic', '', ''),\n",
       " ('05/07/2019', '', '', ''),\n",
       " ('', '', '60', ''),\n",
       " ('14/01/2019', '', '', ''),\n",
       " ('03/07/2019', '', '', ''),\n",
       " ('02/11/2019', '', '', ''),\n",
       " ('', 'Training', '', ''),\n",
       " ('23/02/2019', '', '', ''),\n",
       " ('05/06/2019', '', '', ''),\n",
       " ('06/03/2019', '', '', ''),\n",
       " ('', 'Open', '', ''),\n",
       " ('', 'Regularization', '', ''),\n",
       " ('11/11/2019', '', '', ''),\n",
       " ('', 'Goblet', '', ''),\n",
       " ('03/09/2019', '', '', ''),\n",
       " ('', 'Virtual', '', ''),\n",
       " ('27/10/2019', '', '', ''),\n",
       " ('', 'Google', '', ''),\n",
       " ('24/04/2019', '', '', ''),\n",
       " ('14/03/2019', '', '', ''),\n",
       " ('', '', '20', ''),\n",
       " ('12/12/2019', '', '', ''),\n",
       " ('', 'Noah', '', ''),\n",
       " ('', '', '2', ''),\n",
       " ('', 'Ana', '', ''),\n",
       " ('', 'Theory', '', ''),\n",
       " ('05/09/2019', '', '', ''),\n",
       " ('', '', '26', ''),\n",
       " ('', 'Automata', '', ''),\n",
       " ('30/09/2019', '', '', ''),\n",
       " ('', 'Conditional', '', ''),\n",
       " ('', '', '14', ''),\n",
       " ('', 'Structure', '', ''),\n",
       " ('30/06/2019', '', '', ''),\n",
       " ('', 'Development', '', ''),\n",
       " ('15/02/2019', '', '', ''),\n",
       " ('24/02/2019', '', '', ''),\n",
       " ('', 'Beta', '', ''),\n",
       " ('03/11/2019', '', '', ''),\n",
       " ('', '', '22', ''),\n",
       " ('28/01/2019', '', '', ''),\n",
       " ('', 'Installation', '', ''),\n",
       " ('', 'Phoenix', '', ''),\n",
       " ('', 'Resolution', '', ''),\n",
       " ('29/05/2019', '', '', ''),\n",
       " ('', 'Control', '', ''),\n",
       " ('', 'Convolutional', '', ''),\n",
       " ('', 'Multi', '', ''),\n",
       " ('07/12/2018', '', '', ''),\n",
       " ('', 'Sets', '', ''),\n",
       " ('11/06/2019', '', '', ''),\n",
       " ('17/10/2019', '', '', ''),\n",
       " ('', 'Rule', '', ''),\n",
       " ('22/04/2019', '', '', ''),\n",
       " ('', 'Section', '', ''),\n",
       " ('', 'Chapter', '', ''),\n",
       " ('', 'Receiving', '', ''),\n",
       " ('', 'Arguments', '', ''),\n",
       " ('23/07/2019', '', '', ''),\n",
       " ('06/09/2019', '', '', ''),\n",
       " ('16/10/2019', '', '', ''),\n",
       " ('', 'Linguistica', '', ''),\n",
       " ('', 'Testes', '', ''),\n",
       " ('', 'Processing', '', ''),\n",
       " ('', 'Present', '', ''),\n",
       " ('07/02/2019', '', '', ''),\n",
       " ('', 'Issues', '', ''),\n",
       " ('', 'Rest', '', ''),\n",
       " ('', 'Hip', '', ''),\n",
       " ('', 'Fairness', '', ''),\n",
       " ('', 'Motion', '', ''),\n",
       " ('', 'Infer', '', ''),\n",
       " ('', 'Lecture', '', ''),\n",
       " ('', 'Insoutenable', '', ''),\n",
       " ('10/03/2019', '', '', ''),\n",
       " ('', 'Representations', '', ''),\n",
       " ('', 'Antoine', '', ''),\n",
       " ('', 'Der', '', ''),\n",
       " ('03/03/2019', '', '', ''),\n",
       " ('', 'Style', '', ''),\n",
       " ('26/09/2019', '', '', ''),\n",
       " ('', 'Reinforcement', '', ''),\n",
       " ('', 'Basic', '', ''),\n",
       " ('', '', '62', ''),\n",
       " ('', 'Pragm', '', ''),\n",
       " ('', 'Week', '', ''),\n",
       " ('', 'Contructions', '', ''),\n",
       " ('', '', '2011', ''),\n",
       " ('', 'Subsumption', '', ''),\n",
       " ('18/09/2019', '', '', ''),\n",
       " ('10/12/2019', '', '', ''),\n",
       " ('19/01/2019', '', '', ''),\n",
       " ('', 'Cap', '', ''),\n",
       " ('', '', '50', ''),\n",
       " ('09/10/2019', '', '', ''),\n",
       " ('', 'Improving', '', ''),\n",
       " ('24/03/2019', '', '', ''),\n",
       " ('10/07/2019', '', '', ''),\n",
       " ('09/07/2019', '', '', ''),\n",
       " ('', 'Competitive', '', ''),\n",
       " ('', 'Generative', '', ''),\n",
       " ('', 'World', '', ''),\n",
       " ('09/12/2019', '', '', ''),\n",
       " ('', 'Nets', '', ''),\n",
       " ('', '', '3', ''),\n",
       " ('21/02/2019', '', '', ''),\n",
       " ('20/08/2019', '', '', ''),\n",
       " ('08/02/2019', '', '', ''),\n",
       " ('26/08/2019', '', '', ''),\n",
       " ('', 'Verticalized', '', ''),\n",
       " ('', 'Papers', '', ''),\n",
       " ('', 'Probability', '', ''),\n",
       " ('', 'Special', '', ''),\n",
       " ('28/12/2019', '', '', ''),\n",
       " ('', '', '56', ''),\n",
       " ('', 'Teoria', '', ''),\n",
       " ('', 'Mega', '', ''),\n",
       " ('', '', '23', ''),\n",
       " ('', 'Penguin', '', ''),\n",
       " ('04/04/2019', '', '', ''),\n",
       " ('22/05/2019', '', '', ''),\n",
       " ('', '', '53', ''),\n",
       " ('05/12/2019', '', '', ''),\n",
       " ('22/07/2019', '', '', ''),\n",
       " ('17/12/2018', '', '', ''),\n",
       " ('01/12/2019', '', '', ''),\n",
       " ('', 'Beyond', '', ''),\n",
       " ('', 'Excel', '', ''),\n",
       " ('16/01/2019', '', '', ''),\n",
       " ('', 'Legerete', '', ''),\n",
       " ('', 'Sintaxe', '', ''),\n",
       " ('', 'Physics', '', ''),\n",
       " ('', 'Texture', '', ''),\n",
       " ('', 'Methods', '', ''),\n",
       " ('20/06/2019', '', '', ''),\n",
       " ('18/08/2019', '', '', ''),\n",
       " ('14/09/2019', '', '', ''),\n",
       " ('20/09/2019', '', '', ''),\n",
       " ('', 'Particular', '', ''),\n",
       " ('', 'Labeling', '', ''),\n",
       " ('', '', '5', ''),\n",
       " ('', 'Loss', '', ''),\n",
       " ('', 'Words', '', ''),\n",
       " ('', 'Mind', '', ''),\n",
       " ('', 'Arch', '', ''),\n",
       " ('', 'Solutions', '', ''),\n",
       " ('21/11/2019', '', '', ''),\n",
       " ('13/12/2018', '', '', ''),\n",
       " ('22/06/2019', '', '', ''),\n",
       " ('11/12/2019', '', '', ''),\n",
       " ('27/12/2018', '', '', ''),\n",
       " ('', 'Contos', '', ''),\n",
       " ('', '', '43', ''),\n",
       " ('25/03/2019', '', '', ''),\n",
       " ('', 'Tolstoi', '', ''),\n",
       " ('', 'Friday', '', ''),\n",
       " ('06/04/2019', '', '', ''),\n",
       " ('23/04/2019', '', '', ''),\n",
       " ('', 'Analysing', '', ''),\n",
       " ('25/02/2019', '', '', ''),\n",
       " ('', 'Harry', '', ''),\n",
       " ('', 'Machine', '', ''),\n",
       " ('', 'Design', '', ''),\n",
       " ('', 'Prince', '', ''),\n",
       " ('', 'Research', '', ''),\n",
       " ('14/08/2019', '', '', ''),\n",
       " ('', 'Searching', '', ''),\n",
       " ('', 'Python', '', ''),\n",
       " ('06/11/2019', '', '', ''),\n",
       " ('', 'Grammars', '', ''),\n",
       " ('26/02/2019', '', '', ''),\n",
       " ('28/06/2019', '', '', ''),\n",
       " ('', 'Tuesday', '', ''),\n",
       " ('07/10/2019', '', '', ''),\n",
       " ('', 'Asking', '', ''),\n",
       " ('', 'Do', '', ''),\n",
       " ('', 'Limitations', '', ''),\n",
       " ('', 'Part', '', ''),\n",
       " ('', 'Temporal', '', ''),\n",
       " ('', 'Comunica', '', ''),\n",
       " ('', 'Gym', '', ''),\n",
       " ('27/08/2019', '', '', ''),\n",
       " ('', 'Interfce', '', ''),\n",
       " ('12/08/2019', '', '', ''),\n",
       " ('', 'To', '', ''),\n",
       " ('11/05/2019', '', '', ''),\n",
       " ('', 'Discretas', '', ''),\n",
       " ('', 'Relative', '', ''),\n",
       " ('', '', '59', ''),\n",
       " ('', 'Spinal', '', ''),\n",
       " ('', 'Action', '', ''),\n",
       " ('27/05/2019', '', '', ''),\n",
       " ('03/06/2019', '', '', ''),\n",
       " ('03/04/2019', '', '', ''),\n",
       " ('09/05/2019', '', '', ''),\n",
       " ('18/07/2019', '', '', ''),\n",
       " ('', 'Sapiens', '', ''),\n",
       " ('01/02/2019', '', '', ''),\n",
       " ('', 'Intro', '', ''),\n",
       " ('14/06/2019', '', '', ''),\n",
       " ('', 'From', '', ''),\n",
       " ('', 'Real', '', ''),\n",
       " ('20/04/2019', '', '', ''),\n",
       " ('13/02/2019', '', '', ''),\n",
       " ('18/05/2019', '', '', ''),\n",
       " ('', 'Introduction', '', ''),\n",
       " ('', 'Power', '', ''),\n",
       " ('20/11/2019', '', '', ''),\n",
       " ('05/03/2019', '', '', ''),\n",
       " ('', 'Morfologia', '', ''),\n",
       " ('07/06/2019', '', '', ''),\n",
       " ('05/01/2019', '', '', ''),\n",
       " ('17/06/2019', '', '', ''),\n",
       " ('', '', '11', ''),\n",
       " ('', 'Inference', '', ''),\n",
       " ('03/05/2019', '', '', ''),\n",
       " ('', '', '42', ''),\n",
       " ('', 'Age', '', ''),\n",
       " ('', 'Afterword', '', ''),\n",
       " ('', 'Problem', '', ''),\n",
       " ('', 'Classify', '', ''),\n",
       " ('25/10/2019', '', '', ''),\n",
       " ('', '', '44', ''),\n",
       " ('01/07/2019', '', '', ''),\n",
       " ('08/12/2019', '', '', ''),\n",
       " ('30/12/2018', '', '', ''),\n",
       " ('06/12/2019', '', '', ''),\n",
       " ('', 'Neural', '', ''),\n",
       " ('23/10/2019', '', '', ''),\n",
       " ('', '', '64', ''),\n",
       " ('09/02/2019', '', '', ''),\n",
       " ('08/10/2019', '', '', ''),\n",
       " ('', '', '58', ''),\n",
       " ('10/06/2019', '', '', ''),\n",
       " ('', 'Class', '', ''),\n",
       " ('', 'Auto', '', ''),\n",
       " ('13/05/2019', '', '', ''),\n",
       " ('22/03/2019', '', '', ''),\n",
       " ('', 'Recovery', '', ''),\n",
       " ('', 'Dependency', '', ''),\n",
       " ('', 'Calculus', '', ''),\n",
       " ('15/09/2019', '', '', ''),\n",
       " ('26/06/2019', '', '', ''),\n",
       " ('', 'Tools', '', ''),\n",
       " ('24/08/2019', '', '', ''),\n",
       " ('', 'Robot', '', ''),\n",
       " ('15/08/2019', '', '', ''),\n",
       " ('', '', '54', ''),\n",
       " ('01/09/2019', '', '', ''),\n",
       " ('25/07/2019', '', '', ''),\n",
       " ('01/03/2019', '', '', ''),\n",
       " ('10/01/2019', '', '', ''),\n",
       " ('', 'Sorcerer', '', ''),\n",
       " ('', 'Dependencies', '', ''),\n",
       " ('', 'Dostoyevsky', '', ''),\n",
       " ('', 'List', '', ''),\n",
       " ('04/02/2019', '', '', ''),\n",
       " ('', 'Transforms', '', ''),\n",
       " ('16/09/2019', '', '', ''),\n",
       " ('30/08/2019', '', '', ''),\n",
       " ('', 'Logic', '', ''),\n",
       " ('', 'Stone', '', ''),\n",
       " ('', 'Social', '', ''),\n",
       " ('12/02/2019', '', '', ''),\n",
       " ('21/10/2019', '', '', ''),\n",
       " ('10/02/2019', '', '', ''),\n",
       " ('', 'Spelling', '', ''),\n",
       " ('06/06/2019', '', '', ''),\n",
       " ('', 'Recurrent', '', ''),\n",
       " ('', 'Senten', '', ''),\n",
       " ('', 'Application', '', ''),\n",
       " ('', 'Probabilidades', '', ''),\n",
       " ('18/12/2018', '', '', ''),\n",
       " ('', 'Trm', '', ''),\n",
       " ('', 'Buying', '', ''),\n",
       " ('', 'Separation', '', ''),\n",
       " ('', 'Long', '', ''),\n",
       " ('', 'Meaning', '', ''),\n",
       " ('', 'Higher', '', ''),\n",
       " ('23/08/2019', '', '', ''),\n",
       " ('', '', '8', ''),\n",
       " ('15/03/2019', '', '', ''),\n",
       " ('21/12/2018', '', '', ''),\n",
       " ('29/10/2019', '', '', ''),\n",
       " ('13/08/2019', '', '', ''),\n",
       " ...}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "def load(f):\n",
    "    file = open(f, 'r')\n",
    "    raw = file.read()\n",
    "    return raw\n",
    "\n",
    "raw = load('C:\\\\Users\\\\seidi\\\\Documents\\\\(mapped) Important\\\\DailyToDo.txt')\n",
    "\n",
    "pattern1 = r'(?x)([.\\-:])'\n",
    "matches1 = nltk.regexp_tokenize(raw, pattern1)\n",
    "set(matches1)\n",
    "\n",
    "pattern2 = r'''(?x)\n",
    "    (\\d+/\\d+/\\d+)        # dates\n",
    "    |([A-Z][a-z]+)       # Names - not working because everything is title cased on the corpus\n",
    "    |(\\$?\\d+(\\.\\d+)?%?)  # Monetary Amounts\n",
    "'''\n",
    "\n",
    "matches2 = nltk.regexp_tokenize(raw, pattern2)\n",
    "set(matches2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Rewrite the following loop as a list comprehension:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "result = []\n",
    "for word in sent:\n",
    "    word_len = (word, len(word))\n",
    "    result.append(word_len)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tuple([(word, len(word)) for word in sent])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Define a string raw containing a sentence of your own choosing. Now, split raw on some character other than space, such as 's'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['making a raw ',\n",
       " 'entence to be ',\n",
       " \"plit in '\",\n",
       " \"' in\",\n",
       " 'tead on the ',\n",
       " 'pace',\n",
       " '']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = \"making a raw sentence to be split in 's' instead on the spaces\"\n",
    "\n",
    "raw.split('s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Write a for loop to print out the characters of a string, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "r\n",
      "a\n",
      "w\n",
      " \n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "l\n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "'\n",
      "s\n",
      "'\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "e\n",
      "a\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "c\n",
      "e\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "for character in raw:\n",
    "    print(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ What is the difference between calling split on a string with no argument or with  ' ' as the argument, e.g. sent.split() versus sent.split(' ')? What happens when the string being split contains tab characters, consecutive space characters, or a sequence of tabs and spaces? (In IDLE you will need to use '\\t' to enter a tab character.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Create a variable words containing a list of words. Experiment with words.sort() and sorted(words). What is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'just', 'list', 'list', 'of', 'of', 'words', 'words']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['just', 'a', 'list', 'of', 'words', 'list', 'of', 'words']\n",
    "\n",
    "\n",
    "sorted(words)\n",
    "\n",
    "words.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Explore the difference between strings and integers by typing the following at a Python prompt: \"3\" * 7 and 3 * 7. Try converting between strings and integers using int(\"3\") and str(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3333333'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'3333333'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"3\"*7 # Repeat string 3 seven times\n",
    "3*7   # Do operation 3*7\n",
    "\n",
    "int(\"3\")*7\n",
    "str(3)*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Use a text editor to create a file called prog.py containing the single line  monty = 'Monty Python'. Next, start up a new session with the Python interpreter, and enter the expression monty at the prompt. You will get an error from the interpreter. Now, try the following (note that you have to leave off the .py part of the filename):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'>>> from prog import monty\n",
    "\n",
    "'>>> monty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, Python should return with a value. You can also try import prog, in which case Python should be able to evaluate the expression prog.monty at the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prog import monty\n",
    "monty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ What happens when the formatting strings %6s and %-6s are used to display strings that are longer than six characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a sentence with more than 6 characters'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'this is a sentence with more than 6 characters'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'this is a sentence with more than 6 characters'\n",
    "'%6s'%format(sent)\n",
    "'%-6s'%format(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "◑ Read in some text from a corpus, tokenize it, and print the list of all wh-word types that occur. (wh-words in English are used in questions, relative clauses and exclamations: who, which, what, and so on.) Print them in order. Are any words duplicated in this list, because of the presence of case distinctions or punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>', 'ToDo', 'List', '01/12/2018', '(', 'Saturnday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '0', '.', 'Preface', '[', 'DONE', ']', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '1.Language', 'Processing', 'and', 'Python', '[', 'DONE', ']', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '1.Language', 'Processing', 'and', 'Python', '-', 'Exercises', '[', 'DONE', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Prerequisites', 'and', 'Prework', '[', 'DONE', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Introduction', 'to', 'Machine', 'Learning', '[', 'DONE', ']', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '1', '.', 'Introduction', '[', 'DONE', ']', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '1', '-', 'Introduction', 'to', 'Deep', 'Learning', '[', '--', '--', 'EVENT', 'TODAY', ':', 'New', 'Year', '--', '--', ']', '<', '_____________________________________________', 'Week', '1', '_____________________________________________', '>', 'ToDo', 'List', '02/12/2018', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '03/12/2018', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '04/12/2018', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '05/12/2018', '(', 'Wednesday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '4', '.', 'Doing', 'Things', '-', 'Verbs', ';', 'Personal', 'Pronouns', '<', '>', 'ToDo', 'List', '06/12/2018', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '07/12/2018', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '08/12/2018', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '2', '_____________________________________________', '>', 'ToDo', 'List', '09/12/2018', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '10/12/2018', '(', 'Monday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Descending', 'into', 'ML', '[', 'DONE', ']', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '2', '.', 'Installation', 'and', 'Setup', '[', 'DONE', ']', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '1', '.', 'Introduction', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '1', '[', 'DONE', ']', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '2', '-', 'Deep', 'Sequence', 'Modeling', '<', '>', 'ToDo', 'List', '11/12/2018', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '12/12/2018', '(', 'Wednesday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '1', '.', 'Introduction', '[', 'DONE', ']', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '2', '.', 'Accessing', 'Text', 'Corpora', 'and', 'Lexical', 'Resources', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '2', '<', '>', 'ToDo', 'List', '13/12/2018', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '14/12/2018', '(', 'Friday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '1', '.', 'Introduction', '-', 'Exercises', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Problem', 'Set', '1', '[', 'DONE', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '1', '.', 'Linguagem', ',', 'Língua', ',', 'Linguística', '<', '>', 'ToDo', 'List', '15/12/2018', '(', 'Saturnday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '1', '.', 'Introduction', '-', 'Exercises', '[', 'DONE', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Reducing', 'Loss', '[', 'DONE', ']', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '1', '<', '_____________________________________________', 'Week', '3', '_____________________________________________', '>', 'ToDo', 'List', '16/12/2018', '(', 'Sunday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '3', '<', '>', 'ToDo', 'List', '17/12/2018', '(', 'Monday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Introduction', 'and', 'scope', '<', '>', 'ToDo', 'List', '18/12/2018', '(', 'Tuesday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '2', '.', 'Regular', 'Expressions', 'and', 'Automata', '[', 'DONE', ']', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '1', '.', 'Using', 'neural', 'nets', 'to', 'recognize', 'handwritten', 'digits', '<', '>', 'ToDo', 'List', '19/12/2018', '(', 'Wednesday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '3', '.', 'What', 'is', 'Machine', 'Learning', '?', '[', 'DONE', ']', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '3', '-', 'Deep', 'Computer', 'Vision', '[', '--', '--', 'EVENT', 'TODAY', ':', 'Beach', '--', '--', ']', '<', '>', 'ToDo', 'List', '20/12/2018', '(', 'Thursday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '1', '.', 'Fonética', '[', 'DONE', ']', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '1', '-', 'A', 'Morte', 'de', 'Stalin', '[', '--', '--', 'EVENT', 'TODAY', ':', 'Beach', '--', '--', ']', '<', '>', 'ToDo', 'List', '21/12/2018', '(', 'Friday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '2', '.', 'Regular', 'Expressions', 'and', 'Automata', '-', 'Exercises', '[', '--', '--', 'EVENT', 'TODAY', ':', 'Beach', '--', '--', ']', '<', '>', 'ToDo', 'List', '22/12/2018', '(', 'Saturnday', ')', ':', '[', 'LATE', '!', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '1', '.', 'Linguagem', ',', 'Língua', ',', 'Linguística', '-', 'Exercícios', '<', '_____________________________________________', 'Week', '4', '_____________________________________________', '>', 'ToDo', 'List', '23/12/2018', '(', 'Sunday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '4', '<', '>', 'ToDo', 'List', '24/12/2018', '(', 'Monday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '3', '.', 'N-Grams', '[', 'DONE', ']', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '2', '[', 'DONE', ']', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Reasoning', ':', 'goal', 'trees', 'and', 'problem', 'solving', '<', '>', 'ToDo', 'List', '25/12/2018', '(', 'Tuesday', ')', ':', '[', 'DONE', ']', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '1', '[', '--', '--', 'EVENT', 'TODAY', ':', 'Christmas', '--', '--', ']', '<', '>', 'ToDo', 'List', '26/12/2018', '(', 'Wednesday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'First', 'Steps', 'with', 'TF', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '5', '<', '>', 'ToDo', 'List', '27/12/2018', '(', 'Thursday', ')', ':', '[', 'LATE', '!', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '3', '.', 'N-Grams', '-', 'Exercises', '[', 'DONE', ']', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '1', '.', 'Fonética', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '28/12/2018', '(', 'Friday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '4', '.', 'Crash', 'Course', 'Overview', '[', 'DONE', ']', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '2', '.', 'Intelligent', 'Agents', '[', 'DONE', ']', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '4', '-', 'Deep', 'Generative', 'Models', '[', 'DONE', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '2', '.', 'A', 'Comunicação', 'Humana', '[', 'DONE', ']', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '2', '.', 'How', 'the', 'backpropagation', 'algorithm', 'works', ',', 'Part', '1', '<', '>', 'ToDo', 'List', '29/12/2018', '(', 'Saturnday', ')', ':', '[', 'LATE', '!', ']', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '2', '.', 'Intelligent', 'Agents', '-', 'Exercises', '[', '--', '--', 'EVENT', 'TODAY', ':', 'Chacara', '--', '--', ']', '<', '_____________________________________________', 'Week', '5', '_____________________________________________', '>', 'ToDo', 'List', '30/12/2018', '(', 'Sunday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '5', '.', 'Asking', 'Questions', ';', 'The', 'Prepositional', 'Case', '[', 'DONE', ']', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '6', '.', 'Possession', ';', 'Going', 'Places', ';', 'The', 'Accusative', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '4', '.', 'Naive', 'Bayes', 'Classification', 'and', 'Sentiment', '<', '>', 'ToDo', 'List', '31/12/2018', '(', 'Monday', ')', ':', '[', 'LATE', '!', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Generalization', '[', 'DONE', ']', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Reasoning', ':', 'goal', 'trees', 'and', 'rule-based', 'expert', 'systems', '[', 'LATE', '!', ']', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '2', '-', 'O', 'Demônio', 'do', 'Meio-Dia', '[', '--', '--', 'EVENT', 'TODAY', ':', 'End', 'of', 'Year', '--', '--', ']', '<', '>', 'ToDo', 'List', '01/01/2019', '(', 'Tuesday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '6', '[', 'DONE', ']', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '1', '-', 'Deep', 'Learning', '<', '>', 'ToDo', 'List', '02/01/2019', '(', 'Wednesday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '4', '.', 'Naive', 'Bayes', 'Classification', 'and', 'Sentiment', '-', 'Exercises', '[', 'DONE', ']', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '1', '-', 'Introduction', '<', '>', 'ToDo', 'List', '03/01/2019', '(', 'Thursday', ')', ':', '[', 'LATE', '!', ']', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '3', '.', 'Processing', 'Raw', 'Text', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Problem', 'Set', '2', '[', 'LATE', '!', ']', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '2', '.', 'Fonologia', '[', 'LATE', '!', ']', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '2', '.', 'How', 'the', 'backpropagation', 'algorithm', 'works', ',', 'Part', '2', '<', '>', 'ToDo', 'List', '04/01/2019', '(', 'Friday', ')', ':', '[', 'LATE', '!', ']', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Training', 'and', 'Test', 'Sets', '[', 'LATE', '!', ']', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '3', '.', 'Resolution', 'of', 'Problems', 'by', 'Means', 'of', 'Searching', '[', 'DONE', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'http', ':', '//www.cplusplus.com/doc/tutorial/pointers/', '[', 'LATE', '!', ']', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '7', '[', 'LATE', '!', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '2', '.', 'A', 'Comunicação', 'Humana', '-', 'Exercícios', '[', 'DONE', ']', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '2', '-', 'Gettting', 'off', 'from', 'zero', '<', '>', 'ToDo', 'List', '05/01/2019', '(', 'Saturnday', ')', ':', '[', 'DONE', ']', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '5', '.', 'Logistic', 'Regression', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '3', '.', 'Improving', 'the', 'way', 'neural', 'networks', 'learn', ',', 'Part', '1', '<', '_____________________________________________', 'Week', '6', '_____________________________________________', '>', 'ToDo', 'List', '06/01/2019', '(', 'Sunday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '5', '.', 'Introduction', 'to', 'Neural', 'Networks', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '5', '-', 'Deep', 'Reinforcement', 'Learning', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '3', '.', 'Improving', 'the', 'way', 'neural', 'networks', 'learn', ',', 'Part', '2', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '3', '-', 'Fundaments', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '1', '-', 'Preliminary', 'Algebra', '<', '>', 'ToDo', 'List', '07/01/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '4', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '8', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '1', ':', 'Rule-Based', 'Systems', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '2', '-', 'Computing', 'Machinery', 'and', 'Intelligency', '<', '>', 'ToDo', 'List', '08/01/2019', '(', 'Tuesday', ')', ':', '[', 'DONE', ']', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '7', '.', 'Describing', 'Things', ':', 'Adjectives', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '5', '.', 'Logistic', 'Regression', '-', 'Exercises', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '3', '.', 'Processing', 'Raw', 'Text', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '5', '[', 'DONE', ']', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '1', '-', 'Test', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '4', '-', 'Important', 'Tools', '<', '>', 'ToDo', 'List', '09/01/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Validation', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '3', '-', 'Harry', 'Potter', 'and', 'the', 'Sorcerer', \"'s\", 'Stone', '<', '>', 'ToDo', 'List', '10/01/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '3', '.', 'Resolution', 'of', 'Problems', 'by', 'Means', 'of', 'Searching', '-', 'Exercises', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Problem', 'Set', '3', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '2', '.', 'Fonologia', '-', 'Exercícios', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '5', '-', 'Learning', 'More', '<', '>', 'ToDo', 'List', '11/01/2019', '(', 'Friday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '6', '.', 'Vector', 'Semantics', '[', 'DONE', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '3', '.', 'Teoria', 'dos', 'Signos', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '1', '-', 'Preliminary', 'Algebra', 'Exercises', '<', '>', 'ToDo', 'List', '12/01/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '1', '.', 'Introdução', 'à', 'Análise', 'Exploratória', 'de', 'Dados', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '6', '-', 'Accelerating', '<', '_____________________________________________', 'Week', '7', '_____________________________________________', '>', 'ToDo', 'List', '13/01/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '4', '.', 'Writing', 'Structured', 'Programs', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '9', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '3', '-', 'Brain-Machine', 'Interfaces', ':', 'From', 'Basic', 'Science', 'to', 'Neuroprotheses', 'and', 'Neuroheabilitation', '<', '>', 'ToDo', 'List', '14/01/2019', '(', 'Monday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '6', '.', 'Vector', 'Semantics', '-', 'Exercises', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Representation', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '6', '[', 'DONE', ']', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Search', ':', 'depth-first', ',', 'hill', 'climbing', ',', 'beam', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '4', '.', 'A', 'visual', 'proof', 'that', 'neural', 'nets', 'can', 'compute', 'any', 'function', ',', 'Part', '1', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '7', '-', 'More', 'Tools', '<', '>', 'ToDo', 'List', '15/01/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '6', '.', 'TensorFlow', 'Basics', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '1', '.', 'Introdução', 'à', 'Análise', 'Exploratória', 'de', 'Dados', '-', 'Exercises', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '6', '-', 'Limitations', 'and', 'New', 'Frontiers', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '4', '.', 'A', 'visual', 'proof', 'that', 'neural', 'nets', 'can', 'compute', 'any', 'function', ',', 'Part', '2', '<', '>', 'ToDo', 'List', '16/01/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '4', '.', 'Beyond', 'Classic', 'Search', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Lecture', '10', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '8', '-', 'User', 'Orientation', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '2', '-', 'Preliminary', 'Calculus', '[', '--', '--', 'EVENT', 'TODAY', ':', 'AASDAP', 'start', '--', '--', ']', '<', '>', 'ToDo', 'List', '17/01/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '8', '.', 'Plurals', ';', 'Spelling', 'Rules', ';', 'Buying', 'Things', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '7', '.', 'Neural', 'Nets', 'and', 'Neural', 'Language', 'Models', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '3', '.', 'Morfologia', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', 'Aurelie', \"'s\", 'Master', '-', 'Part', '1/3', '<', '>', 'ToDo', 'List', '18/01/2019', '(', 'Friday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '4', '.', 'Writing', 'Structured', 'Programs', '-', 'Exercises', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '2', '.', 'Probabilidades', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '3', '.', 'Teoria', 'dos', 'Signos', '-', 'Exercícios', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '9', '-', 'Advanced', 'Formulas', '<', '>', 'ToDo', 'List', '19/01/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Feature', 'Crosses', '+++', '[', 'Task10', '-', 'MIT', '6.096', '-', 'Introduction', 'to', 'C++', ']', 'Problem', 'Set', '4', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '4', '-', 'Towards', 'AI-Complete', 'Question', 'Answering', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '4', '-', 'Harry', 'Potter', 'and', 'the', 'Chamber', 'of', 'Secrets', '<', '_____________________________________________', 'Week', '8', '_____________________________________________', '>', 'ToDo', 'List', '20/01/2019', '(', 'Sunday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '7', '.', 'Neural', 'Nets', 'and', 'Neural', 'Language', 'Models', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '7', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '10', '-', 'Dynamic', 'Tools', '<', '>', 'ToDo', 'List', '21/01/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '2', '.', 'Probabilidades', '-', 'Exercises', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Problem', 'set', '0', 'due', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '2', '-', 'Preliminary', 'Calculus', 'Exercises', '<', '>', 'ToDo', 'List', '22/01/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '4', '.', 'Beyond', 'Classic', 'Search', '-', 'Exercises', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '2', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '11', '<', '>', 'ToDo', 'List', '23/01/2019', '(', 'Wednesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '8', '.', 'Part-of-Speech', 'Tagging', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '5', '.', 'Categorizing', 'and', 'Tagging', 'Words', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '5', '.', 'Why', 'are', 'deep', 'neural', 'networks', 'hard', 'to', 'train', '?', ',', 'Part', '1', '<', '>', 'ToDo', 'List', '24/01/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Regularization', ':', 'Simplicity', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '7', '.', 'Convolutional', 'Neural', 'Networks', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '3', '.', 'Variáveis', 'Aleatórias', 'Discretas', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '7', '-', 'Issues', 'in', 'Image', 'Classification', '(', 'Google', 'Guest', ')', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '3', '.', 'Morfologia', '-', 'Exercícios', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '5', '.', 'Why', 'are', 'deep', 'neural', 'networks', 'hard', 'to', 'train', '?', ',', 'Part', '2', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '12', '<', '>', 'ToDo', 'List', '25/01/2019', '(', 'Friday', ')', ':', '[', 'DONE', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '4', '.', 'A', 'Língua', 'como', 'Objeto', 'da', 'Linguística', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '5', '<', '>', 'ToDo', 'List', '26/01/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '9', '.', 'Numbers', ';', 'The', 'Genitive', 'Case', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '8', '.', 'Part-of-Speech', 'Tagging', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '8', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '13', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '3', '-', 'Complex', 'Numbers', 'and', 'Hyperbolic', 'Functions', '<', '_____________________________________________', 'Week', '9', '_____________________________________________', '>', 'ToDo', 'List', '27/01/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '3', '.', 'Variáveis', 'Aleatórias', 'Discretas', '-', 'Exercises', '<', '>', 'ToDo', 'List', '28/01/2019', '(', 'Monday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '5', '.', 'Categorizing', 'and', 'Tagging', 'Words', '-', 'Exercises', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '5', '.', 'Competitive', 'Search', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Search', ':', 'optimal', ',', 'branch', 'and', 'bound', ',', 'A*', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '14', '<', '>', 'ToDo', 'List', '29/01/2019', '(', 'Tuesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '9', '.', 'Sequence', 'Processing', 'with', 'Recurrent', 'Networks', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Logistic', 'Regression', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '5', '-', 'Harry', 'Potter', 'and', 'the', 'Prisoner', 'of', 'Azkaban', '<', '>', 'ToDo', 'List', '30/01/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '4', '.', 'Medidas', 'Resumo', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', 'Aurelie', \"'s\", 'Master', '-', 'Part', '2/3', '++', '[', 'Task19', '-', 'Udemy', 'Excel', ']', 'Section', '15', '<', '>', 'ToDo', 'List', '31/01/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '4', '.', 'Sintaxe', ':', 'Explorando', 'a', 'Estrutura', 'da', 'Sentença', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '6', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '3', '-', 'Complex', 'Numbers', 'and', 'Hyperbolic', 'Functions', 'Exercises', '<', '>', 'ToDo', 'List', '01/02/2019', '(', 'Friday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '9', '.', 'Sequence', 'Processing', 'with', 'Recurrent', 'Networks', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '9', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '4', '.', 'A', 'Língua', 'como', 'Objeto', 'da', 'Linguística', '-', 'Exercícios', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '6', '.', 'Deep', 'learning', ',', 'Part', '1', '<', '>', 'ToDo', 'List', '02/02/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '6', '.', 'Learning', 'to', 'Classify', 'Text', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '8', '.', 'Recurrent', 'Neural', 'Networks', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '4', '.', 'Medidas', 'Resumo', '-', 'Exercises', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '8', '-', 'Faster', 'ML', 'Development', 'with', 'Tensorflow', '(', 'Google', 'Guest', ')', '++++', '[', 'Task15', '-', 'NN', 'and', 'DL', ']', 'Chapter', '6', '.', 'Deep', 'learning', ',', 'Part', '2', '<', '_____________________________________________', 'Week', '10', '_____________________________________________', '>', 'ToDo', 'List', '03/02/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Classification', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '5', '.', 'Competitive', 'Search', '-', 'Exercises', '<', '>', 'ToDo', 'List', '04/02/2019', '(', 'Monday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '10', '.', \"'To\", 'Have', \"'\", ';', 'More', 'on', 'the', 'Genitive', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '10', '.', 'Formal', 'Grammars', 'of', 'English', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Search', ':', 'games', ',', 'minimax', ',', 'and', 'alpha-beta', '<', '>', 'ToDo', 'List', '05/02/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '5', '.', 'Variáveis', 'Bidimensionais', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '2', '-', 'Test', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '4', '-', 'Series', 'and', 'Limits', '<', '>', 'ToDo', 'List', '06/02/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '7', '<', '>', 'ToDo', 'List', '07/02/2019', '(', 'Thursday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '10', '.', 'Formal', 'Grammars', 'of', 'English', '-', 'Exercises', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '6', '.', 'Learning', 'to', 'Classify', 'Text', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '10', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '4', '.', 'Sintaxe', ':', 'Explorando', 'a', 'Estrutura', 'da', 'Sentença', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '08/02/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Regularisation', ':', 'Sparsity', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '5', '.', 'Variáveis', 'Bidimensionais', '-', 'Exercises', '[', 'DONE', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '5', '.', 'A', 'Competência', 'Linguística', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '6', '-', 'Harry', 'Potter', 'and', 'the', 'Goblet', 'of', 'Fire', '<', '>', 'ToDo', 'List', '09/02/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '6', '.', 'Problems', 'of', 'Restriction', 'Satisfaction', '<', '_____________________________________________', 'Week', '11', '_____________________________________________', '>', 'ToDo', 'List', '10/02/2019', '(', 'Sunday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '11', '.', 'Syntactic', 'Parsing', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '4', '-', 'Series', 'and', 'Limits', 'Exercises', '<', '>', 'ToDo', 'List', '11/02/2019', '(', 'Monday', ')', ':', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '9', '.', 'Miscellaneous', 'Topics', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '6', '.', 'Variáveis', 'Aleatórias', 'Contínuas', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Problem', 'set', '1', 'due', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '9', '-', 'Deep', 'Learning', ',', 'A', 'Personal', 'Perspective', '(', 'NVIDIA', 'Guest', ')', '<', '>', 'ToDo', 'List', '12/02/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '7', '.', 'Extracting', 'Information', 'from', 'Text', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', 'Aurelie', \"'s\", 'Master', '-', 'Part', '3/3', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '8', '<', '>', 'ToDo', 'List', '13/02/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '11', '.', 'The', 'Past', ';', 'Reflexive', 'Verbs', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '11', '.', 'Syntactic', 'Parsing', '-', 'Exercises', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Introduction', 'to', 'Neural', 'Nets', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '11', '<', '>', 'ToDo', 'List', '14/02/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '6', '.', 'Variáveis', 'Aleatórias', 'Contínuas', '-', 'Exercises', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '5', '.', 'Semântica', 'Lexical', '<', '>', 'ToDo', 'List', '15/02/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '6', '.', 'Problems', 'of', 'Restriction', 'Satisfaction', '-', 'Exercises', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '5', '.', 'A', 'Competência', 'Linguística', '-', 'Exercícios', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '5', '-', 'Partial', 'Differentiation', '<', '>', 'ToDo', 'List', '16/02/2019', '(', 'Saturnday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '12', '.', 'Statistical', 'Parsing', '<', '_____________________________________________', 'Week', '12', '_____________________________________________', '>', 'ToDo', 'List', '17/02/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '7', '.', 'Extracting', 'Information', 'from', 'Text', '-', 'Exercises', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '7', '.', 'Inferência', 'Estatística', '-', 'Estimação', '<', '>', 'ToDo', 'List', '18/02/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Training', 'Neural', 'Nets', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '2', ':', 'Basic', 'Search', ',', 'Optimal', 'Search', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '9', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '7', '-', 'Harry', 'Potter', 'and', 'the', 'Order', 'of', 'the', 'Phoenix', '<', '>', 'ToDo', 'List', '19/02/2019', '(', 'Tuesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '12', '.', 'Statistical', 'Parsing', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '12', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '3', '<', '>', 'ToDo', 'List', '20/02/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '10', '.', 'AutoEncoders', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '7', '.', 'Inferência', 'Estatística', '-', 'Estimação', '-', 'Exercises', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '10', '-', 'Beyond', 'Deep', 'Learning', '(', 'IBM', 'Guest', ')', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '5', '-', 'Partial', 'Differentiation', 'Exercises', '<', '>', 'ToDo', 'List', '21/02/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '7', '.', 'Logic', 'Agents', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '5', '.', 'Semântica', 'Lexical', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '22/02/2019', '(', 'Friday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '12', '.', 'The', 'Future', ';', 'Aspect', '.', 'The', 'Dative', 'Case', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '13', '.', 'Dependency', 'Parsing', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '8', '.', 'Analysing', 'Sentence', 'Structure', '[', 'DONE', ']', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '6', '.', 'A', 'Variação', 'Linguística', '<', '>', 'ToDo', 'List', '23/02/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Multi-Class', 'Neural', 'Nets', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '8', '.', 'Inferência', 'Estatística', '-', 'Testes', 'de', 'Hipóteses', '<', '_____________________________________________', 'Week', '13', '_____________________________________________', '>', 'ToDo', 'List', '24/02/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '10', '<', '>', 'ToDo', 'List', '25/02/2019', '(', 'Monday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '13', '.', 'Dependency', 'Parsing', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '13', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Quiz', '1', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '1999', ')', 'Real', 'Time', 'Control', 'of', 'a', 'Robot', 'Arm', 'Using', 'Simultaneously', 'Recorded', 'Neurons', 'in', 'the', 'Motor', 'Cortex', '-', 'K', 'C', 'John', 'et', 'al', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '6', '-', 'Multiple', 'Integrals', '<', '>', 'ToDo', 'List', '26/02/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '8', '.', 'Inferência', 'Estatística', '-', 'Testes', 'de', 'Hipóteses', '-', 'Exercises', '<', '>', 'ToDo', 'List', '27/02/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '8', '.', 'Analysing', 'Sentence', 'Structure', '-', 'Exercises', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '7', '.', 'Logic', 'Agents', '-', 'Exercises', '<', '>', 'ToDo', 'List', '28/02/2019', '(', 'Thursday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '14', '.', 'The', 'Representation', 'of', 'Sentence', 'Meaning', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Embeddings', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '6', '.', 'Semântica', 'Formal', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '8', '-', 'Harry', 'Potter', 'and', 'the', 'Half-Blood', 'Prince', '<', '>', 'ToDo', 'List', '01/03/2019', '(', 'Friday', ')', ':', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '11', '.', 'Reinforcement', 'Learning', 'with', 'OpenAI', 'Gym', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '9', '.', 'Tópicos', 'Especiais', '++', '[', 'Task12', '-', 'MIT', '6.5191', '-', 'Intro', 'to', 'Deep', 'Learning', ']', 'Lecture', '11', '-', 'Computer', 'Vision', 'Meets', 'Social', 'Networks', '(', 'Tencent', 'Guest', ')', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '6', '.', 'A', 'Variação', 'Linguística', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '02/03/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '11', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '6', '-', 'Multiple', 'Integrals', 'Exercises', '<', '_____________________________________________', 'Week', '14', '_____________________________________________', '>', 'ToDo', 'List', '03/03/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '13', '.', 'Aspect', 'in', 'the', 'Past', ';', 'Use', 'of', 'Tenses', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '14', '.', 'The', 'Representation', 'of', 'Sentence', 'Meaning', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '14', '<', '>', 'ToDo', 'List', '04/03/2019', '(', 'Monday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '9', '.', 'Building', 'Feature', 'Based', 'Grammars', '+++', '[', 'Task8', '-', 'Noções', 'de', 'Probabilidade', 'e', 'Estatística', ']', 'Capítulo', '9', '.', 'Tópicos', 'Especiais', '-', 'Exercises', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Constraints', ':', 'interpreting', 'line', 'drawings', '<', '>', 'ToDo', 'List', '05/03/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Production', 'ML', 'Systems', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '8', '.', 'First', 'Order', 'Logic', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '3', '-', 'Test', '<', '>', 'ToDo', 'List', '06/03/2019', '(', 'Wednesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '15', '.', 'Computational', 'Semantics', '<', '>', 'ToDo', 'List', '07/03/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '6', '.', 'Semântica', 'Formal', '-', 'Exercícios', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '7', '-', 'Vector', 'Algebra', '<', '>', 'ToDo', 'List', '08/03/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '7', '.', 'A', 'Mudança', 'Linguística', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '12', '<', '>', 'ToDo', 'List', '09/03/2019', '(', 'Saturnday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '15', '.', 'Computational', 'Semantics', '-', 'Exercises', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '9', '.', 'Building', 'Feature', 'Based', 'Grammars', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '15', '<', '_____________________________________________', 'Week', '15', '_____________________________________________', '>', 'ToDo', 'List', '10/03/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Static', 'vs', '.', 'Dynamic', 'Training', '++', '[', 'Task5', '-', 'Tensor', 'Flow', 'by', 'Udemy', ']', 'Section', '12', '.', 'GAN', '-', 'Generative', 'Adversarial', 'Networks', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '2006', ')', '-', 'Brain', 'Machine', 'Interfaces', '_', 'Past', ',', 'Present', 'and', 'Future', '-', 'A', 'L', 'Mikhail', ',', 'A', 'L', 'N', 'Miguel', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '9', '-', 'Harry', 'Potter', 'and', 'the', 'Deathly', 'Hallows', '<', '>', 'ToDo', 'List', '11/03/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '8', '.', 'First', 'Order', 'Logic', '-', 'Exercises', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Constraints', ':', 'search', ',', 'domain', 'reduction', '<', '>', 'ToDo', 'List', '12/03/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '14', '.', 'Aspect', 'in', 'the', 'Future', ';', 'Impersonal', 'Contructions', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '16', '.', 'Semantic', 'Parsing', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '7', '-', 'Vector', 'Algebra', 'Exercises', '<', '>', 'ToDo', 'List', '13/03/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '14/03/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '10', '.', 'Analysing', 'the', 'Meaning', 'of', 'Sentences', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '7', '.', 'Pragmática', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '13', '<', '>', 'ToDo', 'List', '15/03/2019', '(', 'Friday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '16', '.', 'Semantic', 'Parsing', '-', 'Exercises', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Static', 'vs', '.', 'Dynamic', 'Inference', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '16', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '7', '.', 'A', 'Mudança', 'Linguística', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '16/03/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '16', '_____________________________________________', '>', 'ToDo', 'List', '17/03/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '9', '.', 'Inference', 'in', 'First', 'Order', 'Logic', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '8', '-', 'Matrices', 'and', 'Vector', 'Spaces', '<', '>', 'ToDo', 'List', '18/03/2019', '(', 'Monday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '17', '.', 'Information', 'Extraction', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Constraints', ':', 'visual', 'object', 'recognition', '<', '>', 'ToDo', 'List', '19/03/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '10', '.', 'Analysing', 'the', 'Meaning', 'of', 'Sentences', '-', 'Exercises', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '4', '<', '>', 'ToDo', 'List', '20/03/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Data', 'Dependencies', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '14', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '10', '-', 'Sobrevivendo', 'no', 'Inferno', '-', 'MCs', 'Racionais', '<', '>', 'ToDo', 'List', '21/03/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '15', '.', 'Requests', 'and', 'the', 'Imperative', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '17', '.', 'Information', 'Extraction', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '17', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '7', '.', 'Pragmática', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '22/03/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '8', '.', 'A', 'Linguagem', 'em', 'Uso', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '8', '-', 'Matrices', 'and', 'Vector', 'Spaces', 'Exercises', '<', '>', 'ToDo', 'List', '23/03/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '9', '.', 'Inference', 'in', 'First', 'Order', 'Logic', '-', 'Exercises', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '2010', ')', 'A', 'Novel', 'Verticalized', 'Reducation', 'Device', 'for', 'Spinal', 'Cord', 'Injuries', '_', 'The', 'WalkTrainer', ',', 'from', 'Design', 'to', 'Clinical', 'Trials', '-', 'Y', 'Stauffer', 'et', 'al', '<', '_____________________________________________', 'Week', '17', '_____________________________________________', '>', 'ToDo', 'List', '24/03/2019', '(', 'Sunday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '18', '.', 'Semantic', 'Role', 'Labeling', 'and', 'Arguments', 'Structure', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '11', '.', 'Managing', 'Linguistic', 'Data', '<', '>', 'ToDo', 'List', '25/03/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task4', '-', 'Google', 'ML', 'Crash', 'Course', ']', 'Fairness', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '3', ':', 'Games', ',', 'Minimax', ',', 'Alpha-Beta', '<', '>', 'ToDo', 'List', '26/03/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '15', '<', '>', 'ToDo', 'List', '27/03/2019', '(', 'Wednesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '18', '.', 'Semantic', 'Role', 'Labeling', 'and', 'Arguments', 'Structure', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '18', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '9', '-', 'Normal', 'Modes', '<', '>', 'ToDo', 'List', '28/03/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '8', '.', 'Estudos', 'do', 'Discurso', '<', '>', 'ToDo', 'List', '29/03/2019', '(', 'Friday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '11', '.', 'Managing', 'Linguistic', 'Data', '-', 'Exercises', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '10', '.', 'Classic', 'Planning', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '8', '.', 'A', 'Linguagem', 'em', 'Uso', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '30/03/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '16', '.', 'The', 'Instrumental', 'Case', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '19', '.', 'Lexicon', 'for', 'Sentiment', ',', 'Affect', 'and', 'Connotation', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '11', '-', 'Sapiens', '-', 'Yuval', 'Noah', 'Harari', '<', '_____________________________________________', 'Week', '18', '_____________________________________________', '>', 'ToDo', 'List', '31/03/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '01/04/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Problem', 'set', '2', 'due', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '16', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '9', '-', 'Normal', 'Modes', 'Exercises', '<', '>', 'ToDo', 'List', '02/04/2019', '(', 'Tuesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '19', '.', 'Lexicon', 'for', 'Sentiment', ',', 'Affect', 'and', 'Connotation', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '19', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '4', '-', 'Test', '<', '>', 'ToDo', 'List', '03/04/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task3', '-', 'NLTK', 'Book', ']', 'Chapter', '12', '.', 'Afterword', 'Facing', 'the', 'Language', 'Challenge', '<', '>', 'ToDo', 'List', '04/04/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '10', '.', 'Classic', 'Planning', '-', 'Exercises', '+++', '[', 'Task14', '-', 'Introducao', 'a', 'Linguistica', 'II', ']', 'Capítulo', '8', '.', 'Estudos', 'do', 'Discurso', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '05/04/2019', '(', 'Friday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '20', '.', 'Coreference', 'Resolution', 'and', 'Entity', 'Linking', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '9', '.', 'A', 'Abordagem', 'do', 'Texto', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '2011', ')', 'Future', 'Developments', 'in', 'Brain', 'Machine', 'Interface', 'Research', '-', 'A', 'L', 'Mikhail', '<', '>', 'ToDo', 'List', '06/04/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '10', '-', 'Vector', 'Calculus', '<', '_____________________________________________', 'Week', '19', '_____________________________________________', '>', 'ToDo', 'List', '07/04/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '17', '<', '>', 'ToDo', 'List', '08/04/2019', '(', 'Monday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '17', '.', 'Time', ',', 'Date', ',', 'Age', ';', 'Ordinal', 'Numbers', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '20', '.', 'Coreference', 'Resolution', 'and', 'Entity', 'Linking', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '20', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Introduction', 'to', 'learning', ',', 'nearest', 'neighbors', '<', '>', 'ToDo', 'List', '09/04/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '12', '-', 'A', 'Mulher', 'do', 'Oficial', 'Nazista', '<', '>', 'ToDo', 'List', '10/04/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '11', '.', 'Planning', 'and', 'Action', 'in', 'the', 'Real', 'World', '<', '>', 'ToDo', 'List', '11/04/2019', '(', 'Thursday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '21', '.', 'Discourse', 'Coherence', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '10', '-', 'Vector', 'Calculus', 'Exercises', '<', '>', 'ToDo', 'List', '12/04/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '9', '.', 'A', 'Abordagem', 'do', 'Texto', '-', 'Exercícios', '<', '>', 'ToDo', 'List', '13/04/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '18', '<', '_____________________________________________', 'Week', '20', '_____________________________________________', '>', 'ToDo', 'List', '14/04/2019', '(', 'Sunday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '21', '.', 'Discourse', 'Coherence', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '21', '<', '>', 'ToDo', 'List', '15/04/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'identification', 'trees', ',', 'disorder', '<', '>', 'ToDo', 'List', '16/04/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '11', '.', 'Planning', 'and', 'Action', 'in', 'the', 'Real', 'World', '-', 'Exercises', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '5', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '11', '-', 'Line', ',', 'Surface', 'and', 'Volume', 'Integrals', '<', '>', 'ToDo', 'List', '17/04/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '18', '.', 'The', 'Comparative', ';', 'Suprlatives', ';', 'Relative', 'Clauses', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '22', '.', 'Machine', 'Translation', '<', '>', 'ToDo', 'List', '18/04/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '2013', ')', 'A', 'Brain', 'Machine', 'Interface', 'Enables', 'Bimanual', 'Arm', 'Movemtnts', 'in', 'Monkeys', '-', 'J', 'I', 'Peter', 'et', 'al', '<', '>', 'ToDo', 'List', '19/04/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '10', '.', 'A', 'Aquisição', 'da', 'Linguagem', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '19', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '13', '-', 'Contos', 'Completos', '-', 'Fernando', 'Pessoa', '<', '>', 'ToDo', 'List', '20/04/2019', '(', 'Saturnday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '22', '.', 'Machine', 'Translation', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '22', '<', '_____________________________________________', 'Week', '21', '_____________________________________________', '>', 'ToDo', 'List', '21/04/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '11', '-', 'Line', ',', 'Surface', 'and', 'Volume', 'Integrals', 'Exercises', '<', '>', 'ToDo', 'List', '22/04/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '12', '.', 'Knowledge', 'Representation', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Quiz', '2', '<', '>', 'ToDo', 'List', '23/04/2019', '(', 'Tuesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '23', '.', 'Question', 'Answering', '<', '>', 'ToDo', 'List', '24/04/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '25/04/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '20', '<', '>', 'ToDo', 'List', '26/04/2019', '(', 'Friday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '19', '.', 'The', 'Conditional', ';', 'Obligation', ';', 'Prefixes', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '23', '.', 'Question', 'Answering', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '23', '+++', '[', 'Task13', '-', 'Introdução', 'à', 'Linguistica', 'I', ']', 'Capítulo', '10', '.', 'A', 'Aquisição', 'da', 'Linguagem', '-', 'Exercícios', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '12', '-', 'Fourier', 'Series', '<', '>', 'ToDo', 'List', '27/04/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '22', '_____________________________________________', '>', 'ToDo', 'List', '28/04/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '12', '.', 'Knowledge', 'Representation', '-', 'Exercises', '<', '>', 'ToDo', 'List', '29/04/2019', '(', 'Monday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '24', '.', 'Dialog', 'Systems', 'and', 'Chatbots', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'neural', 'nets', ',', 'back', 'propagation', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '14', '-', 'The', 'Power', '-', 'Naomi', 'Alderman', '<', '>', 'ToDo', 'List', '30/04/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '5', '-', 'Test', '<', '>', 'ToDo', 'List', '01/05/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '2016', ')', 'Assimilation', 'of', 'Virtual', 'Legs', 'and', 'Perception', 'of', 'Floor', 'Texture', 'by', 'COmplete', 'Paraplegic', 'PAtients', 'Receiving', 'Artificial', 'Tactile', 'Feedback', '-', 'S', 'Solaiman', 'et', 'al', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '21', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '12', '-', 'Fourier', 'Series', 'Exercises', '<', '>', 'ToDo', 'List', '02/05/2019', '(', 'Thursday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '24', '.', 'Dialog', 'Systems', 'and', 'Chatbots', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '24', '<', '>', 'ToDo', 'List', '03/05/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '04/05/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '13', '.', 'Quantifying', 'Uncertainty', '<', '_____________________________________________', 'Week', '23', '_____________________________________________', '>', 'ToDo', 'List', '05/05/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '20', '.', 'Verbs', 'of', 'Motion', ';', 'Going', ',', 'Running', ',', 'Bringing', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '25', '.', 'Advanced', 'Dialog', 'Systems', '<', '>', 'ToDo', 'List', '06/05/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '4', ':', 'Neural', 'Nets', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '13', '-', 'Integral', 'Transforms', '<', '>', 'ToDo', 'List', '07/05/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '22', '<', '>', 'ToDo', 'List', '08/05/2019', '(', 'Wednesday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '25', '.', 'Advanced', 'Dialog', 'Systems', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '25', '<', '>', 'ToDo', 'List', '09/05/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '15', '-', 'Superintelligence', '-', 'Nick', 'Bostrom', '<', '>', 'ToDo', 'List', '10/05/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '13', '.', 'Quantifying', 'Uncertainty', '-', 'Exercises', '<', '>', 'ToDo', 'List', '11/05/2019', '(', 'Saturnday', ')', ':', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '26', '.', 'Speech', 'Recognition', 'and', 'Synthesis', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '13', '-', 'Integral', 'Transforms', 'Exercises', '<', '_____________________________________________', 'Week', '24', '_____________________________________________', '>', 'ToDo', 'List', '12/05/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '13/05/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Problem', 'set', '3', 'due', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '23', '<', '>', 'ToDo', 'List', '14/05/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '21', '.', 'Possession', '++++', '[', 'Task2', '-', 'Speech', 'and', 'Language', 'Processing', ']', 'Chapter', '26', '.', 'Speech', 'Recognition', 'and', 'Synthesis', '-', 'Exercises', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '26', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '6', '++', '[', 'Task16', '-', 'AASDAP', 'Papers', ']', '(', '2016', ')', 'Long', 'Trm', 'Training', 'with', 'a', 'Brain', 'Machine', 'Interfce', 'Based', 'Gait', 'Protocol', 'Induces', 'Partial', 'Neurological', 'Recovery', 'in', 'Paraplegic', 'Patients', '-', 'R', 'C', 'D', 'Ana', '<', '>', 'ToDo', 'List', '15/05/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '16/05/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '14', '.', 'Probabilistic', 'Thinking', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '14', '-', 'First', 'Order', 'Ordinary', 'Differential', 'Equations', '<', '>', 'ToDo', 'List', '17/05/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '18/05/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '25', '_____________________________________________', '>', 'ToDo', 'List', '19/05/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '24', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '16', '-', 'Sculpting', 'in', 'Time', '-', 'Andrey', 'Tarkovsky', '<', '>', 'ToDo', 'List', '20/05/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '27', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'genetic', 'algorithms', '<', '>', 'ToDo', 'List', '21/05/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '14', '-', 'First', 'Order', 'Ordinary', 'Differential', 'Equations', 'Exercises', '<', '>', 'ToDo', 'List', '22/05/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '14', '.', 'Probabilistic', 'Thinking', '-', 'Exercises', '<', '>', 'ToDo', 'List', '23/05/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '22', '.', 'Fun', 'with', 'Numbers', '<', '>', 'ToDo', 'List', '24/05/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '25/05/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '25', '<', '_____________________________________________', 'Week', '26', '_____________________________________________', '>', 'ToDo', 'List', '26/05/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '28', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '15', '-', 'Higher-Order', 'Ordinary', 'Differential', 'Equations', '<', '>', 'ToDo', 'List', '27/05/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'sparse', 'spaces', ',', 'phonology', '<', '>', 'ToDo', 'List', '28/05/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '15', '.', 'Temporal', 'Probabilistic', 'Thinking', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '6', '-', 'Test', '<', '>', 'ToDo', 'List', '29/05/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '17', '-', 'Duas', 'Narrativas', 'Fantásticas', '-', 'Fiodor', 'Dostoyevsky', '<', '>', 'ToDo', 'List', '30/05/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '31/05/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '26', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '15', '-', 'Higher-Order', 'Ordinary', 'Differential', 'Equations', 'Exercises', '<', '>', 'ToDo', 'List', '01/06/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '23', '.', 'Time', 'Expressions', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '29', '<', '_____________________________________________', 'Week', '27', '_____________________________________________', '>', 'ToDo', 'List', '02/06/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '03/06/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '15', '.', 'Temporal', 'Probabilistic', 'Thinking', '-', 'Exercises', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'near', 'misses', ',', 'felicity', 'conditions', '<', '>', 'ToDo', 'List', '04/06/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '05/06/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '16', '-', 'Series', 'Solutions', 'of', 'Ordinary', 'Differential', 'Equations', '<', '>', 'ToDo', 'List', '06/06/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '27', '<', '>', 'ToDo', 'List', '07/06/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '30', '<', '>', 'ToDo', 'List', '08/06/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '18', '-', 'Justica', '-', 'Michael', 'J.', 'Sandel', '<', '_____________________________________________', 'Week', '28', '_____________________________________________', '>', 'ToDo', 'List', '09/06/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '16', '.', 'Simple', 'Decisions', 'Taking', '<', '>', 'ToDo', 'List', '10/06/2019', '(', 'Monday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '24', '.', 'Negation', ';', 'Place', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'support', 'vector', 'machines', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '16', '-', 'Series', 'Solutions', 'of', 'Ordinary', 'Differential', 'Equations', 'Exercises', '<', '>', 'ToDo', 'List', '11/06/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '7', '<', '>', 'ToDo', 'List', '12/06/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '28', '<', '>', 'ToDo', 'List', '13/06/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '31', '<', '>', 'ToDo', 'List', '14/06/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '15/06/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '16', '.', 'Simple', 'Decisions', 'Taking', '-', 'Exercises', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '17', '-', 'Eigenfunction', 'Methods', 'for', 'Differential', 'Equations', '<', '_____________________________________________', 'Week', '29', '_____________________________________________', '>', 'ToDo', 'List', '16/06/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '17/06/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '5', ':', 'Support', 'Vector', 'Machines', '<', '>', 'ToDo', 'List', '18/06/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '29', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '19', '-', \"L'Insoutenable\", 'Legerete', 'de', \"L'etre\", '-', 'Milan', 'Kundera', '<', '>', 'ToDo', 'List', '19/06/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '25', '.', 'Diminutives', ';', 'Proper', 'Names', ';', 'Politness', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '32', '<', '>', 'ToDo', 'List', '20/06/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '17', '-', 'Eigenfunction', 'Methods', 'for', 'Differential', 'Equations', 'Exercises', '<', '>', 'ToDo', 'List', '21/06/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '17', '.', 'Complex', 'Decisions', 'Taking', '<', '>', 'ToDo', 'List', '22/06/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '30', '_____________________________________________', '>', 'ToDo', 'List', '23/06/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '24/06/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Problem', 'set', '4', 'due', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '30', '<', '>', 'ToDo', 'List', '25/06/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '33', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '7', '-', 'Test', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '18', '-', 'Special', 'Functions', '<', '>', 'ToDo', 'List', '26/06/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '27/06/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '17', '.', 'Complex', 'Decisions', 'Taking', '-', 'Exercises', '<', '>', 'ToDo', 'List', '28/06/2019', '(', 'Friday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '26', '.', 'Indefinite', 'Pronouns', ';', 'Word', 'Order', ';', 'Writting', 'Letters', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '20', '-', 'Der', 'Kleine', 'Prinz', '-', 'Antoine', 'de', 'Saint-Exupery', '<', '>', 'ToDo', 'List', '29/06/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '31', '_____________________________________________', '>', 'ToDo', 'List', '30/06/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '31', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '18', '-', 'Special', 'Functions', 'Exercises', '<', '>', 'ToDo', 'List', '01/07/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '34', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Quiz', '3', '<', '>', 'ToDo', 'List', '02/07/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '03/07/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '18', '.', 'Learning', 'from', 'Examples', '<', '>', 'ToDo', 'List', '04/07/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '05/07/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '19', '-', 'Quantum', 'Operators', '<', '>', 'ToDo', 'List', '06/07/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '32', '<', '_____________________________________________', 'Week', '32', '_____________________________________________', '>', 'ToDo', 'List', '07/07/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '27', '.', 'Participles', ':', 'Types', 'and', 'Stress', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '35', '<', '>', 'ToDo', 'List', '08/07/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Learning', ':', 'boosting', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '21', '-', 'Guerra', 'e', 'Paz', 'I', '-', 'Liev', 'Tolstoi', '<', '>', 'ToDo', 'List', '09/07/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '18', '.', 'Learning', 'from', 'Examples', '-', 'Exercises', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '8', '<', '>', 'ToDo', 'List', '10/07/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '19', '-', 'Quantum', 'Operators', 'Exercises', '<', '>', 'ToDo', 'List', '11/07/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '12/07/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '33', '<', '>', 'ToDo', 'List', '13/07/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '36', '<', '_____________________________________________', 'Week', '33', '_____________________________________________', '>', 'ToDo', 'List', '14/07/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '15/07/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '19', '.', 'Knowledge', 'in', 'Learning', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '6', ':', 'Boosting', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '20', '-', 'Partial', 'Differential', 'Equations', ':', 'General', 'and', 'Particular', 'Solutions', '<', '>', 'ToDo', 'List', '16/07/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '28', '.', 'Verbal', 'Adverbs', '<', '>', 'ToDo', 'List', '17/07/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '18/07/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '34', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '22', '-', 'Guerra', 'e', 'Paz', 'II', '-', 'Liev', 'Tolstoi', '<', '>', 'ToDo', 'List', '19/07/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '37', '<', '>', 'ToDo', 'List', '20/07/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '20', '-', 'Partial', 'Differential', 'Equations', ':', 'General', 'and', 'Particular', 'Solutions', 'Exercises', '<', '_____________________________________________', 'Week', '34', '_____________________________________________', '>', 'ToDo', 'List', '21/07/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '19', '.', 'Knowledge', 'in', 'Learning', '-', 'Exercises', '<', '>', 'ToDo', 'List', '22/07/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Representations', ':', 'classes', ',', 'trajectories', ',', 'transitions', '<', '>', 'ToDo', 'List', '23/07/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '8', '-', 'Test', '<', '>', 'ToDo', 'List', '24/07/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '35', '<', '>', 'ToDo', 'List', '25/07/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '29', '.', \"'Bookish\", \"'\", 'Style', ';', 'Active', 'Participles', ';', 'Punctuation', ';', 'Short-Form', 'Adjectives', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '38', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '21', '-', 'Partial', 'Differential', 'Equations', ':', 'Separation', 'of', 'Variables', 'and', 'Other', 'Methods', '<', '>', 'ToDo', 'List', '26/07/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '27/07/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '20', '.', 'Learning', 'of', 'Probabilistic', 'Models', '<', '_____________________________________________', 'Week', '35', '_____________________________________________', '>', 'ToDo', 'List', '28/07/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '23', '-', 'Topographie', 'de', 'la', 'Terreur', '<', '>', 'ToDo', 'List', '29/07/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Architectures', ':', 'GPS', ',', 'SOAR', ',', 'Subsumption', ',', 'Society', 'of', 'Mind', '<', '>', 'ToDo', 'List', '30/07/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '36', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '21', '-', 'Partial', 'Differential', 'Equations', ':', 'Separation', 'of', 'Variables', 'and', 'Other', 'Methods', 'Exercises', '<', '>', 'ToDo', 'List', '31/07/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '39', '<', '>', 'ToDo', 'List', '01/08/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '02/08/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '20', '.', 'Learning', 'of', 'Probabilistic', 'Models', '-', 'Exercises', '<', '>', 'ToDo', 'List', '03/08/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task1', '-', 'Penguin', 'Russian', 'Course', ']', 'Chapter', '30', '.', 'Abbreviations', ';', 'Names', 'of', 'Russian', 'Letters', ';', 'Participles', '<', '_____________________________________________', 'Week', '36', '_____________________________________________', '>', 'ToDo', 'List', '04/08/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '22', '-', 'Calculus', 'of', 'Variations', '<', '>', 'ToDo', 'List', '05/08/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'The', 'AI', 'business', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '37', '<', '>', 'ToDo', 'List', '06/08/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '40', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '9', '<', '>', 'ToDo', 'List', '07/08/2019', '(', 'Wednesday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '24', '<', '>', 'ToDo', 'List', '08/08/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '21', '.', 'Learning', 'by', 'Reinforcement', '<', '>', 'ToDo', 'List', '09/08/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '22', '-', 'Calculus', 'of', 'Variations', 'Exercises', '<', '>', 'ToDo', 'List', '10/08/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '37', '_____________________________________________', '>', 'ToDo', 'List', '11/08/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '38', '<', '>', 'ToDo', 'List', '12/08/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '41', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Mega-Recitaiton', '7', ':', 'Near', 'Misses', ',', 'Arch', 'Learning', '<', '>', 'ToDo', 'List', '13/08/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '14/08/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '21', '.', 'Learning', 'by', 'Reinforcement', '-', 'Exercises', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '23', '-', 'Integral', 'Equations', '<', '>', 'ToDo', 'List', '15/08/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '16/08/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '17/08/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '39', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '25', '<', '_____________________________________________', 'Week', '38', '_____________________________________________', '>', 'ToDo', 'List', '18/08/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '42', '<', '>', 'ToDo', 'List', '19/08/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Probabilistic', 'inference', 'I', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '23', '-', 'Integral', 'Equations', 'Exercises', '<', '>', 'ToDo', 'List', '20/08/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '22', '.', 'Natural', 'Language', 'Processing', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '9', '-', 'Test', '<', '>', 'ToDo', 'List', '21/08/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '22/08/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '23/08/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '40', '<', '>', 'ToDo', 'List', '24/08/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '43', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '24', '-', 'Complex', 'Variables', '<', '_____________________________________________', 'Week', '39', '_____________________________________________', '>', 'ToDo', 'List', '25/08/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '26/08/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '22', '.', 'Natural', 'Language', 'Processing', '-', 'Exercises', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Quiz', '4', '<', '>', 'ToDo', 'List', '27/08/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '26', '<', '>', 'ToDo', 'List', '28/08/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '29/08/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '41', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '24', '-', 'Complex', 'Variables', 'Exercises', '<', '>', 'ToDo', 'List', '30/08/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '44', '<', '>', 'ToDo', 'List', '31/08/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '40', '_____________________________________________', '>', 'ToDo', 'List', '01/09/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '23', '.', 'Natural', 'Language', 'for', 'Communication', '<', '>', 'ToDo', 'List', '02/09/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Probabilistic', 'inference', 'II', '<', '>', 'ToDo', 'List', '03/09/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '10', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '25', '-', 'Application', 'of', 'Complex', 'Variables', '<', '>', 'ToDo', 'List', '04/09/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '42', '<', '>', 'ToDo', 'List', '05/09/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '45', '<', '>', 'ToDo', 'List', '06/09/2019', '(', 'Friday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '27', '<', '>', 'ToDo', 'List', '07/09/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '23', '.', 'Natural', 'Language', 'for', 'Communication', '-', 'Exercises', '<', '_____________________________________________', 'Week', '41', '_____________________________________________', '>', 'ToDo', 'List', '08/09/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '25', '-', 'Application', 'of', 'Complex', 'Variables', 'Exercises', '<', '>', 'ToDo', 'List', '09/09/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Model', 'merging', ',', 'cross-modal', 'coupling', ',', 'course', 'summary', '<', '>', 'ToDo', 'List', '10/09/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '43', '<', '>', 'ToDo', 'List', '11/09/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '46', '<', '>', 'ToDo', 'List', '12/09/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '13/09/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '24', '.', 'Perception', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '26', '-', 'Tensors', '<', '>', 'ToDo', 'List', '14/09/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '42', '_____________________________________________', '>', 'ToDo', 'List', '15/09/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '16/09/2019', '(', 'Monday', ')', ':', '++', '[', 'Task11', '-', 'MIT', '6.034', '-', 'AI', ']', 'Problem', 'set', '5', 'due', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '44', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '28', '<', '>', 'ToDo', 'List', '17/09/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '47', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '10', '-', 'Test', '<', '>', 'ToDo', 'List', '18/09/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '26', '-', 'Tensors', 'Exercises', '<', '>', 'ToDo', 'List', '19/09/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '24', '.', 'Perception', '-', 'Exercises', '<', '>', 'ToDo', 'List', '20/09/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '21/09/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '43', '_____________________________________________', '>', 'ToDo', 'List', '22/09/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '45', '<', '>', 'ToDo', 'List', '23/09/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '48', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '27', '-', 'Numerical', 'Methods', '<', '>', 'ToDo', 'List', '24/09/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '25/09/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '25', '.', 'Robotics', '<', '>', 'ToDo', 'List', '26/09/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '29', '<', '>', 'ToDo', 'List', '27/09/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '28/09/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '46', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '27', '-', 'Numerical', 'Methods', 'Exercises', '<', '_____________________________________________', 'Week', '44', '_____________________________________________', '>', 'ToDo', 'List', '29/09/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '49', '<', '>', 'ToDo', 'List', '30/09/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '01/10/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '25', '.', 'Robotics', '-', 'Exercises', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '11', '<', '>', 'ToDo', 'List', '02/10/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '03/10/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '28', '-', 'Group', 'Theory', '<', '>', 'ToDo', 'List', '04/10/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '47', '<', '>', 'ToDo', 'List', '05/10/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '50', '<', '_____________________________________________', 'Week', '45', '_____________________________________________', '>', 'ToDo', 'List', '06/10/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '30', '<', '>', 'ToDo', 'List', '07/10/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '26', '.', 'Philosofical', 'Fundaments', '<', '>', 'ToDo', 'List', '08/10/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '28', '-', 'Group', 'Theory', 'Exercises', '<', '>', 'ToDo', 'List', '09/10/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '10/10/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '48', '<', '>', 'ToDo', 'List', '11/10/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '51', '<', '>', 'ToDo', 'List', '12/10/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '46', '_____________________________________________', '>', 'ToDo', 'List', '13/10/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '26', '.', 'Philosofical', 'Fundaments', '-', 'Exercises', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '29', '-', 'Representation', 'Theory', '<', '>', 'ToDo', 'List', '14/10/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '15/10/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '11', '-', 'Test', '<', '>', 'ToDo', 'List', '16/10/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '49', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '31', '<', '>', 'ToDo', 'List', '17/10/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '52', '<', '>', 'ToDo', 'List', '18/10/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '29', '-', 'Representation', 'Theory', 'Exercises', '<', '>', 'ToDo', 'List', '19/10/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task6', '-', 'Artificial', 'Intelligence', ']', 'Chapter', '27', '.', 'AI', ',', 'Present', 'and', 'Future', '<', '_____________________________________________', 'Week', '47', '_____________________________________________', '>', 'ToDo', 'List', '20/10/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '21/10/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '22/10/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '50', '<', '>', 'ToDo', 'List', '23/10/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '53', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '30', '-', 'Probability', '<', '>', 'ToDo', 'List', '24/10/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '25/10/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '26/10/2019', '(', 'Saturnday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '32', '<', '_____________________________________________', 'Week', '48', '_____________________________________________', '>', 'ToDo', 'List', '27/10/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '28/10/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '51', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '30', '-', 'Probability', 'Exercises', '<', '>', 'ToDo', 'List', '29/10/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '54', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '12', '<', '>', 'ToDo', 'List', '30/10/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '31/10/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '01/11/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '02/11/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '31', '-', 'Statistics', '<', '_____________________________________________', 'Week', '49', '_____________________________________________', '>', 'ToDo', 'List', '03/11/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task17', '-', 'At', 'Least', 'one', 'Paper', 'per', 'Week', ']', 'Paper', '52', '<', '>', 'ToDo', 'List', '04/11/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '55', '<', '>', 'ToDo', 'List', '05/11/2019', '(', 'Tuesday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '33', '<', '>', 'ToDo', 'List', '06/11/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '07/11/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task20', '-', 'Mathematical', 'Methods', 'for', 'Physics', 'and', 'Engineering', ']', 'Chapter', '31', '-', 'Statistics', 'Exercises', '<', '>', 'ToDo', 'List', '08/11/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '09/11/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '50', '_____________________________________________', '>', 'ToDo', 'List', '10/11/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '56', '<', '>', 'ToDo', 'List', '11/11/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '12/11/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '12', '-', 'Test', '<', '>', 'ToDo', 'List', '13/11/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '14/11/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '15/11/2019', '(', 'Friday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '34', '<', '>', 'ToDo', 'List', '16/11/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '57', '<', '_____________________________________________', 'Week', '51', '_____________________________________________', '>', 'ToDo', 'List', '17/11/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '18/11/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '19/11/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '20/11/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '21/11/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '22/11/2019', '(', 'Friday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '58', '<', '>', 'ToDo', 'List', '23/11/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '52', '_____________________________________________', '>', 'ToDo', 'List', '24/11/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '25/11/2019', '(', 'Monday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '35', '<', '>', 'ToDo', 'List', '26/11/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '13', '<', '>', 'ToDo', 'List', '27/11/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '28/11/2019', '(', 'Thursday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '59', '<', '>', 'ToDo', 'List', '29/11/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '30/11/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '53', '_____________________________________________', '>', 'ToDo', 'List', '01/12/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '02/12/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '03/12/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '04/12/2019', '(', 'Wednesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '60', '<', '>', 'ToDo', 'List', '05/12/2019', '(', 'Thursday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '36', '<', '>', 'ToDo', 'List', '06/12/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '07/12/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '54', '_____________________________________________', '>', 'ToDo', 'List', '08/12/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '09/12/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '10/12/2019', '(', 'Tuesday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '61', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '13', '-', 'Test', '<', '>', 'ToDo', 'List', '11/12/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '12/12/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '13/12/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '14/12/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '55', '_____________________________________________', '>', 'ToDo', 'List', '15/12/2019', '(', 'Sunday', ')', ':', '++', '[', 'Task18', '-', 'Books', '2019', ']', 'Book', '37', '<', '>', 'ToDo', 'List', '16/12/2019', '(', 'Monday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '62', '<', '>', 'ToDo', 'List', '17/12/2019', '(', 'Tuesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '18/12/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '19/12/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '20/12/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '21/12/2019', '(', 'Saturnday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '_____________________________________________', 'Week', '56', '_____________________________________________', '>', 'ToDo', 'List', '22/12/2019', '(', 'Sunday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '63', '<', '>', 'ToDo', 'List', '23/12/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '24/12/2019', '(', 'Tuesday', ')', ':', '+', '[', 'Task9', '-', 'Take', 'Off', 'in', 'German', ']', 'Chapter', '14', '<', '>', 'ToDo', 'List', '25/12/2019', '(', 'Wednesday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '26/12/2019', '(', 'Thursday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '27/12/2019', '(', 'Friday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '28/12/2019', '(', 'Saturnday', ')', ':', '+++', '[', 'Task7', '-', 'Principles', 'of', 'Neuroscience', ']', 'Chapter', '64', '<', '_____________________________________________', 'Week', '57', '_____________________________________________', '>', 'ToDo', 'List', '29/12/2019', '(', 'Sunday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<', '>', 'ToDo', 'List', '30/12/2019', '(', 'Monday', ')', ':', '[', '--', '--', 'Rest', '(', 'OR', 'MOVE', 'TASKS', 'FOR', 'TODAY', ')', '--', '--', ']', '<']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import re\n",
    "raw = load('C:\\\\Users\\\\seidi\\\\Documents\\\\(mapped) Important\\\\DailyToDo.txt')\n",
    "tokens = word_tokenize(raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "◑ Create a file consisting of words and (made up) frequencies, where each line consists of a word, the space character, and a positive integer, e.g. fuzzy 53. Read the file into a Python list using open(filename).readlines(). Next, break each line into its two fields using split(), and convert the number into an integer using int(). The result should be a list of the form: [['fuzzy', 53], ...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "◑ Write code to access a favorite webpage and extract some text from it. For example, access a weather site and extract the forecast top temperature for your town or city today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
